{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5FjHhNkIZ30t"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Yfpvkx1Z9po",
    "outputId": "c7212d17-319a-44db-c1c6-496150eb952b"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Yr8FvwxBaJER"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BEqYNm2BlG4"
   },
   "source": [
    "Here we are performing mini-batch gradient with batch size of 10.\n",
    "\n",
    "Below is the code for tanh activation function with epoch size of 25, 50, 100, 150 and fluctuating hidden layer size with number of neurons as 25, 50, 100, 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hV2DTv3Zb9AL",
    "outputId": "d0e86066-e2ff-4f45-c004-fb42201df092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 1.8672158902287483\n",
      "Epoch [2/25], Loss: 1.1071572224919994\n",
      "Epoch [3/25], Loss: 0.9356303595801194\n",
      "Epoch [4/25], Loss: 0.8322071065107981\n",
      "Epoch [5/25], Loss: 0.7645340378321708\n",
      "Epoch [6/25], Loss: 0.7105897632464766\n",
      "Epoch [7/25], Loss: 0.6732550571883719\n",
      "Epoch [8/25], Loss: 0.6395777036771179\n",
      "Epoch [9/25], Loss: 0.6145410864837467\n",
      "Epoch [10/25], Loss: 0.5915775176510215\n",
      "Epoch [11/25], Loss: 0.5702574436962604\n",
      "Epoch [12/25], Loss: 0.5541890967525542\n",
      "Epoch [13/25], Loss: 0.5400053734096388\n",
      "Epoch [14/25], Loss: 0.5265809397827834\n",
      "Epoch [15/25], Loss: 0.514138159904629\n",
      "Epoch [16/25], Loss: 0.503865550834996\n",
      "Epoch [17/25], Loss: 0.49343966679212947\n",
      "Epoch [18/25], Loss: 0.48345363628243404\n",
      "Epoch [19/25], Loss: 0.47503812522844724\n",
      "Epoch [20/25], Loss: 0.4663930728007108\n",
      "Epoch [21/25], Loss: 0.4587594906529412\n",
      "Epoch [22/25], Loss: 0.4538186256568879\n",
      "Epoch [23/25], Loss: 0.4460026771426201\n",
      "Epoch [24/25], Loss: 0.4411475485575696\n",
      "Epoch [25/25], Loss: 0.43620817029336467\n",
      "Epoch 25 Accuracy = 86.93%, Loss = 0.1160\n",
      "Epoch [1/50], Loss: 1.7985392437974612\n",
      "Epoch [2/50], Loss: 1.1258725145881374\n",
      "Epoch [3/50], Loss: 0.9559830594869951\n",
      "Epoch [4/50], Loss: 0.8629545377319058\n",
      "Epoch [5/50], Loss: 0.8012782576481501\n",
      "Epoch [6/50], Loss: 0.7529122786199053\n",
      "Epoch [7/50], Loss: 0.7169152025394142\n",
      "Epoch [8/50], Loss: 0.681964918628335\n",
      "Epoch [9/50], Loss: 0.6531127375904471\n",
      "Epoch [10/50], Loss: 0.6225178562017779\n",
      "Epoch [11/50], Loss: 0.5949573128372431\n",
      "Epoch [12/50], Loss: 0.5733047528006137\n",
      "Epoch [13/50], Loss: 0.5525835689306259\n",
      "Epoch [14/50], Loss: 0.5370749746259923\n",
      "Epoch [15/50], Loss: 0.5187048813598231\n",
      "Epoch [16/50], Loss: 0.5053321877100194\n",
      "Epoch [17/50], Loss: 0.4929893035215015\n",
      "Epoch [18/50], Loss: 0.4825838177042703\n",
      "Epoch [19/50], Loss: 0.47305642920018487\n",
      "Epoch [20/50], Loss: 0.4641725483636061\n",
      "Epoch [21/50], Loss: 0.45435617375249665\n",
      "Epoch [22/50], Loss: 0.44737089351719866\n",
      "Epoch [23/50], Loss: 0.4404065000154078\n",
      "Epoch [24/50], Loss: 0.43517490844707934\n",
      "Epoch [25/50], Loss: 0.42884955762544025\n",
      "Epoch [26/50], Loss: 0.4223640283467248\n",
      "Epoch [27/50], Loss: 0.41699553027624886\n",
      "Epoch [28/50], Loss: 0.4121121830002715\n",
      "Epoch [29/50], Loss: 0.4072096935849016\n",
      "Epoch [30/50], Loss: 0.4028691687079457\n",
      "Epoch [31/50], Loss: 0.397377460640079\n",
      "Epoch [32/50], Loss: 0.39497961780397844\n",
      "Epoch [33/50], Loss: 0.3897983789949988\n",
      "Epoch [34/50], Loss: 0.3857367752273567\n",
      "Epoch [35/50], Loss: 0.38254373471143965\n",
      "Epoch [36/50], Loss: 0.3791784593183547\n",
      "Epoch [37/50], Loss: 0.37559644821006805\n",
      "Epoch [38/50], Loss: 0.37204673650263187\n",
      "Epoch [39/50], Loss: 0.36919143906841057\n",
      "Epoch [40/50], Loss: 0.3664773981656569\n",
      "Epoch [41/50], Loss: 0.3636322462965424\n",
      "Epoch [42/50], Loss: 0.3611616000747308\n",
      "Epoch [43/50], Loss: 0.35816443002270537\n",
      "Epoch [44/50], Loss: 0.3553318478325382\n",
      "Epoch [45/50], Loss: 0.3535369943470384\n",
      "Epoch [46/50], Loss: 0.35164777585631235\n",
      "Epoch [47/50], Loss: 0.34944359088378646\n",
      "Epoch [48/50], Loss: 0.3466688098659118\n",
      "Epoch [49/50], Loss: 0.3450948882379259\n",
      "Epoch [50/50], Loss: 0.34257488883519543\n",
      "Epoch 50 Accuracy = 89.31%, Loss = 0.0313\n",
      "Epoch [1/100], Loss: 1.9038865137845278\n",
      "Epoch [2/100], Loss: 1.1626981796100735\n",
      "Epoch [3/100], Loss: 0.9819514270797371\n",
      "Epoch [4/100], Loss: 0.8773880563452839\n",
      "Epoch [5/100], Loss: 0.8018255278244615\n",
      "Epoch [6/100], Loss: 0.745307748414576\n",
      "Epoch [7/100], Loss: 0.6956387842024366\n",
      "Epoch [8/100], Loss: 0.6608603920638562\n",
      "Epoch [9/100], Loss: 0.633518719236056\n",
      "Epoch [10/100], Loss: 0.6106343091558665\n",
      "Epoch [11/100], Loss: 0.5880057573237767\n",
      "Epoch [12/100], Loss: 0.5712881041386475\n",
      "Epoch [13/100], Loss: 0.5551476346611356\n",
      "Epoch [14/100], Loss: 0.5402101508670797\n",
      "Epoch [15/100], Loss: 0.5250201865540196\n",
      "Epoch [16/100], Loss: 0.5130143174255888\n",
      "Epoch [17/100], Loss: 0.5026888476163149\n",
      "Epoch [18/100], Loss: 0.4928481415466716\n",
      "Epoch [19/100], Loss: 0.483064105244043\n",
      "Epoch [20/100], Loss: 0.4742187951464827\n",
      "Epoch [21/100], Loss: 0.46533814222769193\n",
      "Epoch [22/100], Loss: 0.45686674799211324\n",
      "Epoch [23/100], Loss: 0.4502597184687232\n",
      "Epoch [24/100], Loss: 0.4445606346555675\n",
      "Epoch [25/100], Loss: 0.4369192049211512\n",
      "Epoch [26/100], Loss: 0.4312174998608728\n",
      "Epoch [27/100], Loss: 0.42742096824912973\n",
      "Epoch [28/100], Loss: 0.4232319829367722\n",
      "Epoch [29/100], Loss: 0.4186508305001383\n",
      "Epoch [30/100], Loss: 0.4145270438001802\n",
      "Epoch [31/100], Loss: 0.40999168145811804\n",
      "Epoch [32/100], Loss: 0.4052482124972157\n",
      "Epoch [33/100], Loss: 0.40245301247077686\n",
      "Epoch [34/100], Loss: 0.39986223707844815\n",
      "Epoch [35/100], Loss: 0.394336294127473\n",
      "Epoch [36/100], Loss: 0.393032354839767\n",
      "Epoch [37/100], Loss: 0.38825884369931496\n",
      "Epoch [38/100], Loss: 0.38543469839884587\n",
      "Epoch [39/100], Loss: 0.38286515497462825\n",
      "Epoch [40/100], Loss: 0.3823527350211516\n",
      "Epoch [41/100], Loss: 0.3781498548759458\n",
      "Epoch [42/100], Loss: 0.3751148832446585\n",
      "Epoch [43/100], Loss: 0.37283623865991833\n",
      "Epoch [44/100], Loss: 0.37032022066476444\n",
      "Epoch [45/100], Loss: 0.3672233339852343\n",
      "Epoch [46/100], Loss: 0.36439428813414027\n",
      "Epoch [47/100], Loss: 0.3610482348043782\n",
      "Epoch [48/100], Loss: 0.35994929721144336\n",
      "Epoch [49/100], Loss: 0.3572246282007545\n",
      "Epoch [50/100], Loss: 0.3545315604568459\n",
      "Epoch [51/100], Loss: 0.35313908125056576\n",
      "Epoch [52/100], Loss: 0.3516515738628805\n",
      "Epoch [53/100], Loss: 0.3493182919874477\n",
      "Epoch [54/100], Loss: 0.34789538072639453\n",
      "Epoch [55/100], Loss: 0.34604691877836985\n",
      "Epoch [56/100], Loss: 0.3453033690978773\n",
      "Epoch [57/100], Loss: 0.34360812346450986\n",
      "Epoch [58/100], Loss: 0.34034797324441995\n",
      "Epoch [59/100], Loss: 0.3399011118067429\n",
      "Epoch [60/100], Loss: 0.33739250965137035\n",
      "Epoch [61/100], Loss: 0.33687069425405936\n",
      "Epoch [62/100], Loss: 0.3350065137031488\n",
      "Epoch [63/100], Loss: 0.33348384708554174\n",
      "Epoch [64/100], Loss: 0.332427662865414\n",
      "Epoch [65/100], Loss: 0.3300578754269518\n",
      "Epoch [66/100], Loss: 0.3287477371087298\n",
      "Epoch [67/100], Loss: 0.32782996211123344\n",
      "Epoch [68/100], Loss: 0.32592675753263756\n",
      "Epoch [69/100], Loss: 0.3255727212023921\n",
      "Epoch [70/100], Loss: 0.32393461755476893\n",
      "Epoch [71/100], Loss: 0.32235792761668564\n",
      "Epoch [72/100], Loss: 0.320919307507885\n",
      "Epoch [73/100], Loss: 0.31985557005678616\n",
      "Epoch [74/100], Loss: 0.3180818059837135\n",
      "Epoch [75/100], Loss: 0.31727263422636315\n",
      "Epoch [76/100], Loss: 0.3157396357377681\n",
      "Epoch [77/100], Loss: 0.3151109066650582\n",
      "Epoch [78/100], Loss: 0.3133852665234978\n",
      "Epoch [79/100], Loss: 0.3112352237290082\n",
      "Epoch [80/100], Loss: 0.31080367101402956\n",
      "Epoch [81/100], Loss: 0.30950868175535773\n",
      "Epoch [82/100], Loss: 0.3082925528922739\n",
      "Epoch [83/100], Loss: 0.3069025585208243\n",
      "Epoch [84/100], Loss: 0.3062941970312192\n",
      "Epoch [85/100], Loss: 0.30541285492371145\n",
      "Epoch [86/100], Loss: 0.3031575172871041\n",
      "Epoch [87/100], Loss: 0.3022654065187089\n",
      "Epoch [88/100], Loss: 0.3012675919154038\n",
      "Epoch [89/100], Loss: 0.30067258605671426\n",
      "Epoch [90/100], Loss: 0.29958917256910356\n",
      "Epoch [91/100], Loss: 0.29824830502046584\n",
      "Epoch [92/100], Loss: 0.2977648839866742\n",
      "Epoch [93/100], Loss: 0.29642871062038467\n",
      "Epoch [94/100], Loss: 0.29529215320983593\n",
      "Epoch [95/100], Loss: 0.29462022651126607\n",
      "Epoch [96/100], Loss: 0.2938870454362283\n",
      "Epoch [97/100], Loss: 0.29314410518916945\n",
      "Epoch [98/100], Loss: 0.29203750304831194\n",
      "Epoch [99/100], Loss: 0.2915910704615526\n",
      "Epoch [100/100], Loss: 0.28988858606736173\n",
      "Epoch 100 Accuracy = 90.34%, Loss = 0.3020\n",
      "Epoch [1/150], Loss: 2.078257644037406\n",
      "Epoch [2/150], Loss: 1.2514604914883773\n",
      "Epoch [3/150], Loss: 1.0095398429060976\n",
      "Epoch [4/150], Loss: 0.878159227023522\n",
      "Epoch [5/150], Loss: 0.8000993441691001\n",
      "Epoch [6/150], Loss: 0.7451997756424049\n",
      "Epoch [7/150], Loss: 0.7030691456372539\n",
      "Epoch [8/150], Loss: 0.6655340776840846\n",
      "Epoch [9/150], Loss: 0.634678201517711\n",
      "Epoch [10/150], Loss: 0.6109930192468067\n",
      "Epoch [11/150], Loss: 0.5901693824262668\n",
      "Epoch [12/150], Loss: 0.573033446527707\n",
      "Epoch [13/150], Loss: 0.5576245262815307\n",
      "Epoch [14/150], Loss: 0.5443723643794656\n",
      "Epoch [15/150], Loss: 0.5321468449061115\n",
      "Epoch [16/150], Loss: 0.5193293037141363\n",
      "Epoch [17/150], Loss: 0.5098328062246243\n",
      "Epoch [18/150], Loss: 0.49837242455407976\n",
      "Epoch [19/150], Loss: 0.49011321636630845\n",
      "Epoch [20/150], Loss: 0.4816438417031119\n",
      "Epoch [21/150], Loss: 0.4737612758297473\n",
      "Epoch [22/150], Loss: 0.4664581887057672\n",
      "Epoch [23/150], Loss: 0.4590145133823777\n",
      "Epoch [24/150], Loss: 0.45277376640898487\n",
      "Epoch [25/150], Loss: 0.4478114860358958\n",
      "Epoch [26/150], Loss: 0.44222560547385364\n",
      "Epoch [27/150], Loss: 0.43607195929593096\n",
      "Epoch [28/150], Loss: 0.4320941035406043\n",
      "Epoch [29/150], Loss: 0.4266453897388031\n",
      "Epoch [30/150], Loss: 0.4217894744953761\n",
      "Epoch [31/150], Loss: 0.41789416381840905\n",
      "Epoch [32/150], Loss: 0.41425385042714574\n",
      "Epoch [33/150], Loss: 0.4113694621565131\n",
      "Epoch [34/150], Loss: 0.40838422707871846\n",
      "Epoch [35/150], Loss: 0.40496976027296233\n",
      "Epoch [36/150], Loss: 0.40170544263968866\n",
      "Epoch [37/150], Loss: 0.39880796197863916\n",
      "Epoch [38/150], Loss: 0.3987947644327457\n",
      "Epoch [39/150], Loss: 0.39361668776379277\n",
      "Epoch [40/150], Loss: 0.39192189173214137\n",
      "Epoch [41/150], Loss: 0.3882117162778353\n",
      "Epoch [42/150], Loss: 0.385731103543813\n",
      "Epoch [43/150], Loss: 0.3827976176176841\n",
      "Epoch [44/150], Loss: 0.3798389006834477\n",
      "Epoch [45/150], Loss: 0.37813982160699866\n",
      "Epoch [46/150], Loss: 0.3756476268181577\n",
      "Epoch [47/150], Loss: 0.3727045243003716\n",
      "Epoch [48/150], Loss: 0.37004051481404654\n",
      "Epoch [49/150], Loss: 0.36832959795479353\n",
      "Epoch [50/150], Loss: 0.36628798057651146\n",
      "Epoch [51/150], Loss: 0.36402339770815645\n",
      "Epoch [52/150], Loss: 0.36257514207437636\n",
      "Epoch [53/150], Loss: 0.36054668578583127\n",
      "Epoch [54/150], Loss: 0.3588291037962772\n",
      "Epoch [55/150], Loss: 0.3568213111483492\n",
      "Epoch [56/150], Loss: 0.35520287856878713\n",
      "Epoch [57/150], Loss: 0.35397626949101685\n",
      "Epoch [58/150], Loss: 0.3515306093399413\n",
      "Epoch [59/150], Loss: 0.3499671000100983\n",
      "Epoch [60/150], Loss: 0.34865705913119016\n",
      "Epoch [61/150], Loss: 0.34695968467431765\n",
      "Epoch [62/150], Loss: 0.3456124187967119\n",
      "Epoch [63/150], Loss: 0.3439469043305144\n",
      "Epoch [64/150], Loss: 0.342971684706863\n",
      "Epoch [65/150], Loss: 0.34107822755056744\n",
      "Epoch [66/150], Loss: 0.339482829628357\n",
      "Epoch [67/150], Loss: 0.3382170016394618\n",
      "Epoch [68/150], Loss: 0.33655851480939114\n",
      "Epoch [69/150], Loss: 0.33510151152483497\n",
      "Epoch [70/150], Loss: 0.3333794130192449\n",
      "Epoch [71/150], Loss: 0.3322908692097602\n",
      "Epoch [72/150], Loss: 0.33051312661947063\n",
      "Epoch [73/150], Loss: 0.3302842536284588\n",
      "Epoch [74/150], Loss: 0.3277857874527884\n",
      "Epoch [75/150], Loss: 0.32665502320261053\n",
      "Epoch [76/150], Loss: 0.3253200624481154\n",
      "Epoch [77/150], Loss: 0.32401284981891515\n",
      "Epoch [78/150], Loss: 0.323765543786188\n",
      "Epoch [79/150], Loss: 0.32178143541002646\n",
      "Epoch [80/150], Loss: 0.32041220441383\n",
      "Epoch [81/150], Loss: 0.31999818932202956\n",
      "Epoch [82/150], Loss: 0.31886118138348685\n",
      "Epoch [83/150], Loss: 0.3171232521493609\n",
      "Epoch [84/150], Loss: 0.3162683202335611\n",
      "Epoch [85/150], Loss: 0.3156846112307782\n",
      "Epoch [86/150], Loss: 0.3153221737385417\n",
      "Epoch [87/150], Loss: 0.3135735251364919\n",
      "Epoch [88/150], Loss: 0.31343772566271944\n",
      "Epoch [89/150], Loss: 0.311782855922201\n",
      "Epoch [90/150], Loss: 0.3114766372423619\n",
      "Epoch [91/150], Loss: 0.3095115146287717\n",
      "Epoch [92/150], Loss: 0.3097072711417762\n",
      "Epoch [93/150], Loss: 0.30885402637642495\n",
      "Epoch [94/150], Loss: 0.30805842304617786\n",
      "Epoch [95/150], Loss: 0.30763437727140264\n",
      "Epoch [96/150], Loss: 0.30608438435864327\n",
      "Epoch [97/150], Loss: 0.3057748762036984\n",
      "Epoch [98/150], Loss: 0.3051283396900011\n",
      "Epoch [99/150], Loss: 0.3042734139529057\n",
      "Epoch [100/150], Loss: 0.30322416268056257\n",
      "Epoch [101/150], Loss: 0.302609066916164\n",
      "Epoch [102/150], Loss: 0.3016712964315278\n",
      "Epoch [103/150], Loss: 0.3014767230177919\n",
      "Epoch [104/150], Loss: 0.30024071845893435\n",
      "Epoch [105/150], Loss: 0.2993134454108464\n",
      "Epoch [106/150], Loss: 0.29834857146286714\n",
      "Epoch [107/150], Loss: 0.2987154812484514\n",
      "Epoch [108/150], Loss: 0.2974766891763235\n",
      "Epoch [109/150], Loss: 0.2964871864680511\n",
      "Epoch [110/150], Loss: 0.29575288537338684\n",
      "Epoch [111/150], Loss: 0.2953288524268816\n",
      "Epoch [112/150], Loss: 0.29487747185009844\n",
      "Epoch [113/150], Loss: 0.29451819003528606\n",
      "Epoch [114/150], Loss: 0.29303636300501723\n",
      "Epoch [115/150], Loss: 0.2928390564578585\n",
      "Epoch [116/150], Loss: 0.29205238265342387\n",
      "Epoch [117/150], Loss: 0.2918841307257147\n",
      "Epoch [118/150], Loss: 0.2903532918857721\n",
      "Epoch [119/150], Loss: 0.29024417919370654\n",
      "Epoch [120/150], Loss: 0.28962176404132817\n",
      "Epoch [121/150], Loss: 0.28873205777925126\n",
      "Epoch [122/150], Loss: 0.2882992978668772\n",
      "Epoch [123/150], Loss: 0.28735673351647956\n",
      "Epoch [124/150], Loss: 0.28738359597278756\n",
      "Epoch [125/150], Loss: 0.2866161488055562\n",
      "Epoch [126/150], Loss: 0.286643890646752\n",
      "Epoch [127/150], Loss: 0.28584757558458174\n",
      "Epoch [128/150], Loss: 0.2853396196733229\n",
      "Epoch [129/150], Loss: 0.28452423092753937\n",
      "Epoch [130/150], Loss: 0.2840088374293409\n",
      "Epoch [131/150], Loss: 0.2834554082123407\n",
      "Epoch [132/150], Loss: 0.2825872071702033\n",
      "Epoch [133/150], Loss: 0.2828622828987427\n",
      "Epoch [134/150], Loss: 0.2814120119277698\n",
      "Epoch [135/150], Loss: 0.28101169686554933\n",
      "Epoch [136/150], Loss: 0.2807692563071226\n",
      "Epoch [137/150], Loss: 0.28076848188228903\n",
      "Epoch [138/150], Loss: 0.279709799100024\n",
      "Epoch [139/150], Loss: 0.2788734764715967\n",
      "Epoch [140/150], Loss: 0.2788970783983047\n",
      "Epoch [141/150], Loss: 0.2779579288383635\n",
      "Epoch [142/150], Loss: 0.2778518607375057\n",
      "Epoch [143/150], Loss: 0.27724723818013447\n",
      "Epoch [144/150], Loss: 0.2767478655166148\n",
      "Epoch [145/150], Loss: 0.27666224487901975\n",
      "Epoch [146/150], Loss: 0.2758430590943123\n",
      "Epoch [147/150], Loss: 0.27505761504545806\n",
      "Epoch [148/150], Loss: 0.2743967344018941\n",
      "Epoch [149/150], Loss: 0.2745093438982343\n",
      "Epoch [150/150], Loss: 0.27365423293644564\n",
      "Epoch 150 Accuracy = 90.63%, Loss = 0.5662\n",
      "Epoch [1/25], Loss: 1.7854644135336082\n",
      "Epoch [2/25], Loss: 1.0778264691630999\n",
      "Epoch [3/25], Loss: 0.9140876274183393\n",
      "Epoch [4/25], Loss: 0.7986999351345002\n",
      "Epoch [5/25], Loss: 0.7245299896101157\n",
      "Epoch [6/25], Loss: 0.6694427542549869\n",
      "Epoch [7/25], Loss: 0.6321272570844739\n",
      "Epoch [8/25], Loss: 0.6016762750403335\n",
      "Epoch [9/25], Loss: 0.5754331955369562\n",
      "Epoch [10/25], Loss: 0.5556299477107823\n",
      "Epoch [11/25], Loss: 0.536101115697374\n",
      "Epoch [12/25], Loss: 0.5188902913844213\n",
      "Epoch [13/25], Loss: 0.5073871387448162\n",
      "Epoch [14/25], Loss: 0.4940673705798884\n",
      "Epoch [15/25], Loss: 0.48314306312985716\n",
      "Epoch [16/25], Loss: 0.4726007879000778\n",
      "Epoch [17/25], Loss: 0.4644302226882428\n",
      "Epoch [18/25], Loss: 0.45498127341767153\n",
      "Epoch [19/25], Loss: 0.44808322673415146\n",
      "Epoch [20/25], Loss: 0.44232476728595793\n",
      "Epoch [21/25], Loss: 0.43408242805488406\n",
      "Epoch [22/25], Loss: 0.42720181148561337\n",
      "Epoch [23/25], Loss: 0.4218866477521757\n",
      "Epoch [24/25], Loss: 0.4168692451013873\n",
      "Epoch [25/25], Loss: 0.41182632980697476\n",
      "Epoch 25 Accuracy = 87.38%, Loss = 1.0441\n",
      "Epoch [1/50], Loss: 1.8325258670995632\n",
      "Epoch [2/50], Loss: 1.0607668538093566\n",
      "Epoch [3/50], Loss: 0.9090313484705984\n",
      "Epoch [4/50], Loss: 0.8134109920635819\n",
      "Epoch [5/50], Loss: 0.7458543798389534\n",
      "Epoch [6/50], Loss: 0.6937595994186898\n",
      "Epoch [7/50], Loss: 0.6526644990816712\n",
      "Epoch [8/50], Loss: 0.6205101752368113\n",
      "Epoch [9/50], Loss: 0.5913737121950835\n",
      "Epoch [10/50], Loss: 0.5683180401089291\n",
      "Epoch [11/50], Loss: 0.5478924702191725\n",
      "Epoch [12/50], Loss: 0.5310382963769759\n",
      "Epoch [13/50], Loss: 0.5143841599843775\n",
      "Epoch [14/50], Loss: 0.5025492406385019\n",
      "Epoch [15/50], Loss: 0.48870832164554545\n",
      "Epoch [16/50], Loss: 0.4764904069096471\n",
      "Epoch [17/50], Loss: 0.4658582471087575\n",
      "Epoch [18/50], Loss: 0.45673166106175633\n",
      "Epoch [19/50], Loss: 0.4472199180830891\n",
      "Epoch [20/50], Loss: 0.4399294518592457\n",
      "Epoch [21/50], Loss: 0.4317795157286649\n",
      "Epoch [22/50], Loss: 0.42383094457785286\n",
      "Epoch [23/50], Loss: 0.41793792770197613\n",
      "Epoch [24/50], Loss: 0.4127834731681893\n",
      "Epoch [25/50], Loss: 0.4058687304646398\n",
      "Epoch [26/50], Loss: 0.4002330070696771\n",
      "Epoch [27/50], Loss: 0.3946447049283112\n",
      "Epoch [28/50], Loss: 0.38852334379777315\n",
      "Epoch [29/50], Loss: 0.38516947062080725\n",
      "Epoch [30/50], Loss: 0.3804516946078899\n",
      "Epoch [31/50], Loss: 0.3756591668850742\n",
      "Epoch [32/50], Loss: 0.3716753306820368\n",
      "Epoch [33/50], Loss: 0.3676986594566454\n",
      "Epoch [34/50], Loss: 0.36480796877651783\n",
      "Epoch [35/50], Loss: 0.3612361943642609\n",
      "Epoch [36/50], Loss: 0.358384528552182\n",
      "Epoch [37/50], Loss: 0.35491515457443895\n",
      "Epoch [38/50], Loss: 0.350972701100943\n",
      "Epoch [39/50], Loss: 0.3485222225162822\n",
      "Epoch [40/50], Loss: 0.34599075523903594\n",
      "Epoch [41/50], Loss: 0.34261930929357187\n",
      "Epoch [42/50], Loss: 0.34023437133897094\n",
      "Epoch [43/50], Loss: 0.3369069553130927\n",
      "Epoch [44/50], Loss: 0.33441377035109326\n",
      "Epoch [45/50], Loss: 0.3315265793368841\n",
      "Epoch [46/50], Loss: 0.32882522127653163\n",
      "Epoch [47/50], Loss: 0.3268747808660846\n",
      "Epoch [48/50], Loss: 0.3242063713532407\n",
      "Epoch [49/50], Loss: 0.32163697374751793\n",
      "Epoch [50/50], Loss: 0.3195604034367328\n",
      "Epoch 50 Accuracy = 89.46%, Loss = 0.2010\n",
      "Epoch [1/100], Loss: 1.9247312050710121\n",
      "Epoch [2/100], Loss: 1.1245183524042368\n",
      "Epoch [3/100], Loss: 0.9404366885622343\n",
      "Epoch [4/100], Loss: 0.8264530770058434\n",
      "Epoch [5/100], Loss: 0.7538053503942986\n",
      "Epoch [6/100], Loss: 0.69445944539768\n",
      "Epoch [7/100], Loss: 0.6441789767493804\n",
      "Epoch [8/100], Loss: 0.6089271962648879\n",
      "Epoch [9/100], Loss: 0.5788426445039611\n",
      "Epoch [10/100], Loss: 0.5555868155431624\n",
      "Epoch [11/100], Loss: 0.5347713339778906\n",
      "Epoch [12/100], Loss: 0.5171517188418656\n",
      "Epoch [13/100], Loss: 0.5006960694842661\n",
      "Epoch [14/100], Loss: 0.48944983500055966\n",
      "Epoch [15/100], Loss: 0.47569258135122555\n",
      "Epoch [16/100], Loss: 0.4648520890592287\n",
      "Epoch [17/100], Loss: 0.45632335607831676\n",
      "Epoch [18/100], Loss: 0.44844764057391634\n",
      "Epoch [19/100], Loss: 0.4393993439457069\n",
      "Epoch [20/100], Loss: 0.4314655365915969\n",
      "Epoch [21/100], Loss: 0.42584609756587694\n",
      "Epoch [22/100], Loss: 0.4201962387813255\n",
      "Epoch [23/100], Loss: 0.41422910192469137\n",
      "Epoch [24/100], Loss: 0.40894091171740243\n",
      "Epoch [25/100], Loss: 0.4033266294427837\n",
      "Epoch [26/100], Loss: 0.3988121813818192\n",
      "Epoch [27/100], Loss: 0.3951172473781432\n",
      "Epoch [28/100], Loss: 0.38930929663342734\n",
      "Epoch [29/100], Loss: 0.385889629960681\n",
      "Epoch [30/100], Loss: 0.38158818588762855\n",
      "Epoch [31/100], Loss: 0.3777847052764458\n",
      "Epoch [32/100], Loss: 0.3736289172093384\n",
      "Epoch [33/100], Loss: 0.3714875729396008\n",
      "Epoch [34/100], Loss: 0.36830523554685834\n",
      "Epoch [35/100], Loss: 0.36531709106126803\n",
      "Epoch [36/100], Loss: 0.36224641134015595\n",
      "Epoch [37/100], Loss: 0.35925809891568494\n",
      "Epoch [38/100], Loss: 0.35689890508695193\n",
      "Epoch [39/100], Loss: 0.3537963173141082\n",
      "Epoch [40/100], Loss: 0.3518678151109877\n",
      "Epoch [41/100], Loss: 0.3492046397753681\n",
      "Epoch [42/100], Loss: 0.34658258663133407\n",
      "Epoch [43/100], Loss: 0.34480596458756674\n",
      "Epoch [44/100], Loss: 0.3425874363151379\n",
      "Epoch [45/100], Loss: 0.33969977066665885\n",
      "Epoch [46/100], Loss: 0.33769627486821263\n",
      "Epoch [47/100], Loss: 0.3365476570641622\n",
      "Epoch [48/100], Loss: 0.33358018832576153\n",
      "Epoch [49/100], Loss: 0.3317792841351281\n",
      "Epoch [50/100], Loss: 0.32990428631426766\n",
      "Epoch [51/100], Loss: 0.32835153793046873\n",
      "Epoch [52/100], Loss: 0.32714369454219316\n",
      "Epoch [53/100], Loss: 0.32455704152972126\n",
      "Epoch [54/100], Loss: 0.32299517403310163\n",
      "Epoch [55/100], Loss: 0.321263428027276\n",
      "Epoch [56/100], Loss: 0.32018698411714286\n",
      "Epoch [57/100], Loss: 0.3182489414162313\n",
      "Epoch [58/100], Loss: 0.3173406739374623\n",
      "Epoch [59/100], Loss: 0.3147010166514665\n",
      "Epoch [60/100], Loss: 0.3143277956737826\n",
      "Epoch [61/100], Loss: 0.31303910657887657\n",
      "Epoch [62/100], Loss: 0.3114044892283467\n",
      "Epoch [63/100], Loss: 0.30994839827545606\n",
      "Epoch [64/100], Loss: 0.30891585430844376\n",
      "Epoch [65/100], Loss: 0.3078122011537974\n",
      "Epoch [66/100], Loss: 0.3065374302173344\n",
      "Epoch [67/100], Loss: 0.30529819256688157\n",
      "Epoch [68/100], Loss: 0.30425054822443054\n",
      "Epoch [69/100], Loss: 0.3024010630613193\n",
      "Epoch [70/100], Loss: 0.3005883443368754\n",
      "Epoch [71/100], Loss: 0.3004151144512774\n",
      "Epoch [72/100], Loss: 0.2990816800633135\n",
      "Epoch [73/100], Loss: 0.2975682797060969\n",
      "Epoch [74/100], Loss: 0.2966543602221645\n",
      "Epoch [75/100], Loss: 0.29607220318696154\n",
      "Epoch [76/100], Loss: 0.2941938961263125\n",
      "Epoch [77/100], Loss: 0.2939053655869017\n",
      "Epoch [78/100], Loss: 0.2928441272160659\n",
      "Epoch [79/100], Loss: 0.2919333677768397\n",
      "Epoch [80/100], Loss: 0.2905840079874421\n",
      "Epoch [81/100], Loss: 0.2898164663763018\n",
      "Epoch [82/100], Loss: 0.2889320716994504\n",
      "Epoch [83/100], Loss: 0.2881530431867577\n",
      "Epoch [84/100], Loss: 0.2872581535902961\n",
      "Epoch [85/100], Loss: 0.2860021477007928\n",
      "Epoch [86/100], Loss: 0.2850649820330242\n",
      "Epoch [87/100], Loss: 0.2836993230949932\n",
      "Epoch [88/100], Loss: 0.2831461885174892\n",
      "Epoch [89/100], Loss: 0.28253475480697426\n",
      "Epoch [90/100], Loss: 0.2812278594034724\n",
      "Epoch [91/100], Loss: 0.28063567460956984\n",
      "Epoch [92/100], Loss: 0.2797422222751193\n",
      "Epoch [93/100], Loss: 0.27883270054729653\n",
      "Epoch [94/100], Loss: 0.27831581693903235\n",
      "Epoch [95/100], Loss: 0.27730281634194154\n",
      "Epoch [96/100], Loss: 0.2763960453264105\n",
      "Epoch [97/100], Loss: 0.27608012839135093\n",
      "Epoch [98/100], Loss: 0.27522747565138467\n",
      "Epoch [99/100], Loss: 0.2741707316431372\n",
      "Epoch [100/100], Loss: 0.2733358872225508\n",
      "Epoch 100 Accuracy = 90.34%, Loss = 0.0412\n",
      "Epoch [1/150], Loss: 1.8592034041807055\n",
      "Epoch [2/150], Loss: 1.0269344356395305\n",
      "Epoch [3/150], Loss: 0.8598192129532496\n",
      "Epoch [4/150], Loss: 0.7613622236121446\n",
      "Epoch [5/150], Loss: 0.6974826362654567\n",
      "Epoch [6/150], Loss: 0.6495200934422513\n",
      "Epoch [7/150], Loss: 0.6130395945652077\n",
      "Epoch [8/150], Loss: 0.5852386808007335\n",
      "Epoch [9/150], Loss: 0.5591858958105246\n",
      "Epoch [10/150], Loss: 0.5368907832012823\n",
      "Epoch [11/150], Loss: 0.518019115634573\n",
      "Epoch [12/150], Loss: 0.5016267558156202\n",
      "Epoch [13/150], Loss: 0.4867520990821843\n",
      "Epoch [14/150], Loss: 0.4754236589577049\n",
      "Epoch [15/150], Loss: 0.4643250652644783\n",
      "Epoch [16/150], Loss: 0.4542794566421459\n",
      "Epoch [17/150], Loss: 0.44343884371904035\n",
      "Epoch [18/150], Loss: 0.4351166007689511\n",
      "Epoch [19/150], Loss: 0.42609497925732287\n",
      "Epoch [20/150], Loss: 0.41771335939193766\n",
      "Epoch [21/150], Loss: 0.4107190252567331\n",
      "Epoch [22/150], Loss: 0.4036227091864372\n",
      "Epoch [23/150], Loss: 0.3977872738366326\n",
      "Epoch [24/150], Loss: 0.39035263483707483\n",
      "Epoch [25/150], Loss: 0.3839757238812745\n",
      "Epoch [26/150], Loss: 0.37865590839119007\n",
      "Epoch [27/150], Loss: 0.37285423785308375\n",
      "Epoch [28/150], Loss: 0.36762875656333444\n",
      "Epoch [29/150], Loss: 0.3627718004696071\n",
      "Epoch [30/150], Loss: 0.3590904698084729\n",
      "Epoch [31/150], Loss: 0.3544698642875689\n",
      "Epoch [32/150], Loss: 0.35038966325530785\n",
      "Epoch [33/150], Loss: 0.34746361374420426\n",
      "Epoch [34/150], Loss: 0.3438106502178125\n",
      "Epoch [35/150], Loss: 0.3397633754427855\n",
      "Epoch [36/150], Loss: 0.3358276100779573\n",
      "Epoch [37/150], Loss: 0.3318488127498422\n",
      "Epoch [38/150], Loss: 0.3287129389855545\n",
      "Epoch [39/150], Loss: 0.32609970604271316\n",
      "Epoch [40/150], Loss: 0.3229770548332793\n",
      "Epoch [41/150], Loss: 0.32000786617134386\n",
      "Epoch [42/150], Loss: 0.31753682108898645\n",
      "Epoch [43/150], Loss: 0.3140627915115717\n",
      "Epoch [44/150], Loss: 0.3122483430141583\n",
      "Epoch [45/150], Loss: 0.30900119073324217\n",
      "Epoch [46/150], Loss: 0.3065019779847935\n",
      "Epoch [47/150], Loss: 0.30413043137748413\n",
      "Epoch [48/150], Loss: 0.3013368401819219\n",
      "Epoch [49/150], Loss: 0.2996025341859398\n",
      "Epoch [50/150], Loss: 0.2969813555167057\n",
      "Epoch [51/150], Loss: 0.2955818479695202\n",
      "Epoch [52/150], Loss: 0.2923559328545816\n",
      "Epoch [53/150], Loss: 0.2897624774645083\n",
      "Epoch [54/150], Loss: 0.2888923944168103\n",
      "Epoch [55/150], Loss: 0.286498710392431\n",
      "Epoch [56/150], Loss: 0.28517847002181224\n",
      "Epoch [57/150], Loss: 0.2837074323950801\n",
      "Epoch [58/150], Loss: 0.28110663167798583\n",
      "Epoch [59/150], Loss: 0.2804992255876617\n",
      "Epoch [60/150], Loss: 0.27858306614627754\n",
      "Epoch [61/150], Loss: 0.2772462122642901\n",
      "Epoch [62/150], Loss: 0.27581990757615615\n",
      "Epoch [63/150], Loss: 0.2739770139663015\n",
      "Epoch [64/150], Loss: 0.273310767702021\n",
      "Epoch [65/150], Loss: 0.27111481051077135\n",
      "Epoch [66/150], Loss: 0.2697694043163986\n",
      "Epoch [67/150], Loss: 0.2688460995906886\n",
      "Epoch [68/150], Loss: 0.2680831050018702\n",
      "Epoch [69/150], Loss: 0.26608424648627016\n",
      "Epoch [70/150], Loss: 0.2655391793177308\n",
      "Epoch [71/150], Loss: 0.2637326918473312\n",
      "Epoch [72/150], Loss: 0.263502238060891\n",
      "Epoch [73/150], Loss: 0.26177675449855936\n",
      "Epoch [74/150], Loss: 0.2613419868017857\n",
      "Epoch [75/150], Loss: 0.26010970427383046\n",
      "Epoch [76/150], Loss: 0.2585386790595173\n",
      "Epoch [77/150], Loss: 0.25776481900387443\n",
      "Epoch [78/150], Loss: 0.25715190755645745\n",
      "Epoch [79/150], Loss: 0.2551129278982213\n",
      "Epoch [80/150], Loss: 0.2548138815657779\n",
      "Epoch [81/150], Loss: 0.25375206807038436\n",
      "Epoch [82/150], Loss: 0.2526335948976533\n",
      "Epoch [83/150], Loss: 0.2516393052352748\n",
      "Epoch [84/150], Loss: 0.2515935261987227\n",
      "Epoch [85/150], Loss: 0.25032913805393037\n",
      "Epoch [86/150], Loss: 0.24890213702064162\n",
      "Epoch [87/150], Loss: 0.24849972431194814\n",
      "Epoch [88/150], Loss: 0.24753971751224405\n",
      "Epoch [89/150], Loss: 0.2464140535184803\n",
      "Epoch [90/150], Loss: 0.24520187103181768\n",
      "Epoch [91/150], Loss: 0.24497487772007784\n",
      "Epoch [92/150], Loss: 0.24411647968164957\n",
      "Epoch [93/150], Loss: 0.24301233048186016\n",
      "Epoch [94/150], Loss: 0.24249791099736467\n",
      "Epoch [95/150], Loss: 0.24128327418367068\n",
      "Epoch [96/150], Loss: 0.24045664529770147\n",
      "Epoch [97/150], Loss: 0.24007978208968417\n",
      "Epoch [98/150], Loss: 0.23915904007673575\n",
      "Epoch [99/150], Loss: 0.23889493589712463\n",
      "Epoch [100/150], Loss: 0.23793226697132921\n",
      "Epoch [101/150], Loss: 0.23689217237006718\n",
      "Epoch [102/150], Loss: 0.2361160577266322\n",
      "Epoch [103/150], Loss: 0.23533411045613079\n",
      "Epoch [104/150], Loss: 0.23443436050675034\n",
      "Epoch [105/150], Loss: 0.23447646136127878\n",
      "Epoch [106/150], Loss: 0.23317171265600095\n",
      "Epoch [107/150], Loss: 0.23271520379166274\n",
      "Epoch [108/150], Loss: 0.2317664926056362\n",
      "Epoch [109/150], Loss: 0.23153244809732618\n",
      "Epoch [110/150], Loss: 0.23079802669930116\n",
      "Epoch [111/150], Loss: 0.22951579529159546\n",
      "Epoch [112/150], Loss: 0.2288325632333678\n",
      "Epoch [113/150], Loss: 0.22827497383975423\n",
      "Epoch [114/150], Loss: 0.22811836303471744\n",
      "Epoch [115/150], Loss: 0.22747753869049483\n",
      "Epoch [116/150], Loss: 0.22660696366949318\n",
      "Epoch [117/150], Loss: 0.22614058296471679\n",
      "Epoch [118/150], Loss: 0.22510393505787943\n",
      "Epoch [119/150], Loss: 0.2248942054756141\n",
      "Epoch [120/150], Loss: 0.22420875096627665\n",
      "Epoch [121/150], Loss: 0.22372432690152588\n",
      "Epoch [122/150], Loss: 0.223176846376271\n",
      "Epoch [123/150], Loss: 0.22251873014886708\n",
      "Epoch [124/150], Loss: 0.2216608343112942\n",
      "Epoch [125/150], Loss: 0.22101130101195304\n",
      "Epoch [126/150], Loss: 0.22000846848035385\n",
      "Epoch [127/150], Loss: 0.2202499893360849\n",
      "Epoch [128/150], Loss: 0.2193498910278625\n",
      "Epoch [129/150], Loss: 0.21866943711127776\n",
      "Epoch [130/150], Loss: 0.21845452275763577\n",
      "Epoch [131/150], Loss: 0.21800355298126428\n",
      "Epoch [132/150], Loss: 0.2170377339706756\n",
      "Epoch [133/150], Loss: 0.21684083917775812\n",
      "Epoch [134/150], Loss: 0.21632068578153849\n",
      "Epoch [135/150], Loss: 0.21615442124804637\n",
      "Epoch [136/150], Loss: 0.2152349501674374\n",
      "Epoch [137/150], Loss: 0.21514753112468557\n",
      "Epoch [138/150], Loss: 0.2145704428474419\n",
      "Epoch [139/150], Loss: 0.21354305763891898\n",
      "Epoch [140/150], Loss: 0.2135062885202157\n",
      "Epoch [141/150], Loss: 0.2127049283873833\n",
      "Epoch [142/150], Loss: 0.21222754813548333\n",
      "Epoch [143/150], Loss: 0.21201422464403247\n",
      "Epoch [144/150], Loss: 0.2114033221229717\n",
      "Epoch [145/150], Loss: 0.2109682357092776\n",
      "Epoch [146/150], Loss: 0.21070579908850293\n",
      "Epoch [147/150], Loss: 0.21017044277700672\n",
      "Epoch [148/150], Loss: 0.20944006049924063\n",
      "Epoch [149/150], Loss: 0.20865854683918103\n",
      "Epoch [150/150], Loss: 0.20863226001806712\n",
      "Epoch 150 Accuracy = 92.10%, Loss = 0.0139\n",
      "Epoch [1/25], Loss: 2.0056909664360187\n",
      "Epoch [2/25], Loss: 0.898162222209076\n",
      "Epoch [3/25], Loss: 0.7307964513916523\n",
      "Epoch [4/25], Loss: 0.6400069413132344\n",
      "Epoch [5/25], Loss: 0.5786949992527565\n",
      "Epoch [6/25], Loss: 0.53549864076823\n",
      "Epoch [7/25], Loss: 0.5038940866794437\n",
      "Epoch [8/25], Loss: 0.47895631323739263\n",
      "Epoch [9/25], Loss: 0.458391217349718\n",
      "Epoch [10/25], Loss: 0.440558051418125\n",
      "Epoch [11/25], Loss: 0.4251869567537991\n",
      "Epoch [12/25], Loss: 0.41144297178120665\n",
      "Epoch [13/25], Loss: 0.3996835613232106\n",
      "Epoch [14/25], Loss: 0.3881038348007326\n",
      "Epoch [15/25], Loss: 0.3783880753184203\n",
      "Epoch [16/25], Loss: 0.3703586654884275\n",
      "Epoch [17/25], Loss: 0.3620002438035638\n",
      "Epoch [18/25], Loss: 0.35516666027282673\n",
      "Epoch [19/25], Loss: 0.3468173409184286\n",
      "Epoch [20/25], Loss: 0.3401354527954633\n",
      "Epoch [21/25], Loss: 0.33441836749754533\n",
      "Epoch [22/25], Loss: 0.32932127185973026\n",
      "Epoch [23/25], Loss: 0.3230317718582228\n",
      "Epoch [24/25], Loss: 0.31826448285773706\n",
      "Epoch [25/25], Loss: 0.31419543916157755\n",
      "Epoch 25 Accuracy = 88.89%, Loss = 0.1060\n",
      "Epoch [1/50], Loss: 2.054305431266626\n",
      "Epoch [2/50], Loss: 0.8890747044666981\n",
      "Epoch [3/50], Loss: 0.7191507110490153\n",
      "Epoch [4/50], Loss: 0.6367268431006621\n",
      "Epoch [5/50], Loss: 0.5826509345266968\n",
      "Epoch [6/50], Loss: 0.5441107854588578\n",
      "Epoch [7/50], Loss: 0.5148785618655384\n",
      "Epoch [8/50], Loss: 0.48893957084494954\n",
      "Epoch [9/50], Loss: 0.4686155401384458\n",
      "Epoch [10/50], Loss: 0.44959931034936257\n",
      "Epoch [11/50], Loss: 0.43591111194202675\n",
      "Epoch [12/50], Loss: 0.4223938560836638\n",
      "Epoch [13/50], Loss: 0.4112921087522991\n",
      "Epoch [14/50], Loss: 0.40032593994463483\n",
      "Epoch [15/50], Loss: 0.39004554587144713\n",
      "Epoch [16/50], Loss: 0.3809137392923391\n",
      "Epoch [17/50], Loss: 0.3721977628916502\n",
      "Epoch [18/50], Loss: 0.3641843044364359\n",
      "Epoch [19/50], Loss: 0.35728064718547586\n",
      "Epoch [20/50], Loss: 0.35114470282623855\n",
      "Epoch [21/50], Loss: 0.3438517461703159\n",
      "Epoch [22/50], Loss: 0.338133626275463\n",
      "Epoch [23/50], Loss: 0.3325850112598855\n",
      "Epoch [24/50], Loss: 0.3274559917834898\n",
      "Epoch [25/50], Loss: 0.3220816724333757\n",
      "Epoch [26/50], Loss: 0.31800000919607313\n",
      "Epoch [27/50], Loss: 0.31338751680535887\n",
      "Epoch [28/50], Loss: 0.3093855150587624\n",
      "Epoch [29/50], Loss: 0.30571046435654475\n",
      "Epoch [30/50], Loss: 0.3012392639547664\n",
      "Epoch [31/50], Loss: 0.29763093005431196\n",
      "Epoch [32/50], Loss: 0.2944542224078905\n",
      "Epoch [33/50], Loss: 0.2909779092047441\n",
      "Epoch [34/50], Loss: 0.28797121087624694\n",
      "Epoch [35/50], Loss: 0.2848876141694297\n",
      "Epoch [36/50], Loss: 0.2817473950701921\n",
      "Epoch [37/50], Loss: 0.2790722273141922\n",
      "Epoch [38/50], Loss: 0.27575769991594523\n",
      "Epoch [39/50], Loss: 0.27310345827844384\n",
      "Epoch [40/50], Loss: 0.27024360389832874\n",
      "Epoch [41/50], Loss: 0.26763398638976893\n",
      "Epoch [42/50], Loss: 0.2653928767850739\n",
      "Epoch [43/50], Loss: 0.26321078760149735\n",
      "Epoch [44/50], Loss: 0.2605441893191698\n",
      "Epoch [45/50], Loss: 0.2584134988341636\n",
      "Epoch [46/50], Loss: 0.2561577831622368\n",
      "Epoch [47/50], Loss: 0.25413955438924796\n",
      "Epoch [48/50], Loss: 0.2517532654739916\n",
      "Epoch [49/50], Loss: 0.24988600343370732\n",
      "Epoch [50/50], Loss: 0.24812053933111988\n",
      "Epoch 50 Accuracy = 90.65%, Loss = 0.5862\n",
      "Epoch [1/100], Loss: 2.0158937617242336\n",
      "Epoch [2/100], Loss: 0.8785821485233803\n",
      "Epoch [3/100], Loss: 0.7219677100746582\n",
      "Epoch [4/100], Loss: 0.6446014200107505\n",
      "Epoch [5/100], Loss: 0.5929437176433081\n",
      "Epoch [6/100], Loss: 0.5551327316627527\n",
      "Epoch [7/100], Loss: 0.5253527349502158\n",
      "Epoch [8/100], Loss: 0.4988380637167332\n",
      "Epoch [9/100], Loss: 0.47737682159120837\n",
      "Epoch [10/100], Loss: 0.4602693159074212\n",
      "Epoch [11/100], Loss: 0.4442123281986763\n",
      "Epoch [12/100], Loss: 0.42929793218057605\n",
      "Epoch [13/100], Loss: 0.41641327818669377\n",
      "Epoch [14/100], Loss: 0.4049277899493463\n",
      "Epoch [15/100], Loss: 0.3933907841085456\n",
      "Epoch [16/100], Loss: 0.3836267929524183\n",
      "Epoch [17/100], Loss: 0.373838716616078\n",
      "Epoch [18/100], Loss: 0.3645715723466904\n",
      "Epoch [19/100], Loss: 0.357670050167401\n",
      "Epoch [20/100], Loss: 0.35054448603776595\n",
      "Epoch [21/100], Loss: 0.34377781487985826\n",
      "Epoch [22/100], Loss: 0.3378300019844901\n",
      "Epoch [23/100], Loss: 0.3322072113589384\n",
      "Epoch [24/100], Loss: 0.32728913823732486\n",
      "Epoch [25/100], Loss: 0.32112643085536546\n",
      "Epoch [26/100], Loss: 0.31686402661073954\n",
      "Epoch [27/100], Loss: 0.3117830654076145\n",
      "Epoch [28/100], Loss: 0.30761867269861976\n",
      "Epoch [29/100], Loss: 0.3035325616852691\n",
      "Epoch [30/100], Loss: 0.2996487095649354\n",
      "Epoch [31/100], Loss: 0.2954181470042871\n",
      "Epoch [32/100], Loss: 0.2913677092224825\n",
      "Epoch [33/100], Loss: 0.2886225918075846\n",
      "Epoch [34/100], Loss: 0.2850571489705859\n",
      "Epoch [35/100], Loss: 0.28177701103539826\n",
      "Epoch [36/100], Loss: 0.2788674858570642\n",
      "Epoch [37/100], Loss: 0.275734709108908\n",
      "Epoch [38/100], Loss: 0.272811432004557\n",
      "Epoch [39/100], Loss: 0.26996430948291283\n",
      "Epoch [40/100], Loss: 0.26712576822917133\n",
      "Epoch [41/100], Loss: 0.2646719161819589\n",
      "Epoch [42/100], Loss: 0.26225684690300843\n",
      "Epoch [43/100], Loss: 0.2597584835695258\n",
      "Epoch [44/100], Loss: 0.2573261345130935\n",
      "Epoch [45/100], Loss: 0.2552569328720371\n",
      "Epoch [46/100], Loss: 0.2525687335919356\n",
      "Epoch [47/100], Loss: 0.2513740206230238\n",
      "Epoch [48/100], Loss: 0.2485008968077988\n",
      "Epoch [49/100], Loss: 0.24607449567089013\n",
      "Epoch [50/100], Loss: 0.24416058325709308\n",
      "Epoch [51/100], Loss: 0.2427747759001795\n",
      "Epoch [52/100], Loss: 0.2403743446932252\n",
      "Epoch [53/100], Loss: 0.23861822865864574\n",
      "Epoch [54/100], Loss: 0.2367146460697986\n",
      "Epoch [55/100], Loss: 0.2346877432540253\n",
      "Epoch [56/100], Loss: 0.2332029464431883\n",
      "Epoch [57/100], Loss: 0.23176448294403962\n",
      "Epoch [58/100], Loss: 0.23034083834144986\n",
      "Epoch [59/100], Loss: 0.2282832513586618\n",
      "Epoch [60/100], Loss: 0.2265499418519903\n",
      "Epoch [61/100], Loss: 0.225233199135672\n",
      "Epoch [62/100], Loss: 0.22421295893564822\n",
      "Epoch [63/100], Loss: 0.22237130775872113\n",
      "Epoch [64/100], Loss: 0.2208203523340635\n",
      "Epoch [65/100], Loss: 0.21952271062962245\n",
      "Epoch [66/100], Loss: 0.2182726312847032\n",
      "Epoch [67/100], Loss: 0.21696852095165134\n",
      "Epoch [68/100], Loss: 0.21557056455329682\n",
      "Epoch [69/100], Loss: 0.21428053675657915\n",
      "Epoch [70/100], Loss: 0.21265353302659545\n",
      "Epoch [71/100], Loss: 0.21143543029698775\n",
      "Epoch [72/100], Loss: 0.21086232375809535\n",
      "Epoch [73/100], Loss: 0.20921447693843706\n",
      "Epoch [74/100], Loss: 0.20826175204842973\n",
      "Epoch [75/100], Loss: 0.20655488787292658\n",
      "Epoch [76/100], Loss: 0.20606157930565921\n",
      "Epoch [77/100], Loss: 0.2048206264390513\n",
      "Epoch [78/100], Loss: 0.2040109823642221\n",
      "Epoch [79/100], Loss: 0.20257467323310752\n",
      "Epoch [80/100], Loss: 0.2013333424758554\n",
      "Epoch [81/100], Loss: 0.20082372347764127\n",
      "Epoch [82/100], Loss: 0.19933071254085127\n",
      "Epoch [83/100], Loss: 0.1983821347046566\n",
      "Epoch [84/100], Loss: 0.19770747011818457\n",
      "Epoch [85/100], Loss: 0.19659260719597418\n",
      "Epoch [86/100], Loss: 0.19602637479105034\n",
      "Epoch [87/100], Loss: 0.19468615356254546\n",
      "Epoch [88/100], Loss: 0.19345921514134776\n",
      "Epoch [89/100], Loss: 0.1932384223236392\n",
      "Epoch [90/100], Loss: 0.19264545531497182\n",
      "Epoch [91/100], Loss: 0.19131825780146755\n",
      "Epoch [92/100], Loss: 0.19029844497545856\n",
      "Epoch [93/100], Loss: 0.18975519886779754\n",
      "Epoch [94/100], Loss: 0.18912892898901676\n",
      "Epoch [95/100], Loss: 0.18802487545835903\n",
      "Epoch [96/100], Loss: 0.18763116374010375\n",
      "Epoch [97/100], Loss: 0.18659380167615988\n",
      "Epoch [98/100], Loss: 0.1860251232778731\n",
      "Epoch [99/100], Loss: 0.18515906561883944\n",
      "Epoch [100/100], Loss: 0.18438258899876867\n",
      "Epoch 100 Accuracy = 92.16%, Loss = 0.0120\n",
      "Epoch [1/150], Loss: 2.110062101265726\n",
      "Epoch [2/150], Loss: 0.9012303253932429\n",
      "Epoch [3/150], Loss: 0.7013331065361078\n",
      "Epoch [4/150], Loss: 0.6075703901800638\n",
      "Epoch [5/150], Loss: 0.5532981795080316\n",
      "Epoch [6/150], Loss: 0.5153023219597526\n",
      "Epoch [7/150], Loss: 0.4849805474660049\n",
      "Epoch [8/150], Loss: 0.4601449263279792\n",
      "Epoch [9/150], Loss: 0.44199367487228786\n",
      "Epoch [10/150], Loss: 0.4248204703188191\n",
      "Epoch [11/150], Loss: 0.4109954162201223\n",
      "Epoch [12/150], Loss: 0.398886810728504\n",
      "Epoch [13/150], Loss: 0.38674386010318995\n",
      "Epoch [14/150], Loss: 0.3760491033787063\n",
      "Epoch [15/150], Loss: 0.36617553262389263\n",
      "Epoch [16/150], Loss: 0.35802916742636204\n",
      "Epoch [17/150], Loss: 0.34991705557661285\n",
      "Epoch [18/150], Loss: 0.34223005550242186\n",
      "Epoch [19/150], Loss: 0.335154408324083\n",
      "Epoch [20/150], Loss: 0.3282328208045413\n",
      "Epoch [21/150], Loss: 0.3221226206429613\n",
      "Epoch [22/150], Loss: 0.3168318682643197\n",
      "Epoch [23/150], Loss: 0.31094613087639056\n",
      "Epoch [24/150], Loss: 0.30529998973803596\n",
      "Epoch [25/150], Loss: 0.3004495695144093\n",
      "Epoch [26/150], Loss: 0.2961761317634567\n",
      "Epoch [27/150], Loss: 0.29125120570436897\n",
      "Epoch [28/150], Loss: 0.28690961001751325\n",
      "Epoch [29/150], Loss: 0.2835086643974452\n",
      "Epoch [30/150], Loss: 0.2795604695875275\n",
      "Epoch [31/150], Loss: 0.27577938863041346\n",
      "Epoch [32/150], Loss: 0.27248302243847866\n",
      "Epoch [33/150], Loss: 0.2690298740582851\n",
      "Epoch [34/150], Loss: 0.26629971687138704\n",
      "Epoch [35/150], Loss: 0.2628071541886699\n",
      "Epoch [36/150], Loss: 0.2594184460749384\n",
      "Epoch [37/150], Loss: 0.2565295298652491\n",
      "Epoch [38/150], Loss: 0.25364046971249626\n",
      "Epoch [39/150], Loss: 0.25123345192999114\n",
      "Epoch [40/150], Loss: 0.24837457987188827\n",
      "Epoch [41/150], Loss: 0.24586842188689237\n",
      "Epoch [42/150], Loss: 0.2434252529850152\n",
      "Epoch [43/150], Loss: 0.2409383242095743\n",
      "Epoch [44/150], Loss: 0.2385501922306527\n",
      "Epoch [45/150], Loss: 0.23622839580771202\n",
      "Epoch [46/150], Loss: 0.23434963195953362\n",
      "Epoch [47/150], Loss: 0.23189049859779576\n",
      "Epoch [48/150], Loss: 0.23006483403779565\n",
      "Epoch [49/150], Loss: 0.22843315763018715\n",
      "Epoch [50/150], Loss: 0.22629113882648139\n",
      "Epoch [51/150], Loss: 0.22481862756532306\n",
      "Epoch [52/150], Loss: 0.22258985008992022\n",
      "Epoch [53/150], Loss: 0.2209355455310045\n",
      "Epoch [54/150], Loss: 0.21964222469370967\n",
      "Epoch [55/150], Loss: 0.218082309108373\n",
      "Epoch [56/150], Loss: 0.2165018287760904\n",
      "Epoch [57/150], Loss: 0.21439152881520568\n",
      "Epoch [58/150], Loss: 0.21320582449414846\n",
      "Epoch [59/150], Loss: 0.21165737150019656\n",
      "Epoch [60/150], Loss: 0.2099971847827158\n",
      "Epoch [61/150], Loss: 0.20790859222778818\n",
      "Epoch [62/150], Loss: 0.20696672951162326\n",
      "Epoch [63/150], Loss: 0.20496349785915421\n",
      "Epoch [64/150], Loss: 0.20378783934611905\n",
      "Epoch [65/150], Loss: 0.20210544303335093\n",
      "Epoch [66/150], Loss: 0.20084852184752042\n",
      "Epoch [67/150], Loss: 0.19941628325579222\n",
      "Epoch [68/150], Loss: 0.19816670258625527\n",
      "Epoch [69/150], Loss: 0.1964474179428847\n",
      "Epoch [70/150], Loss: 0.19529331953512155\n",
      "Epoch [71/150], Loss: 0.19392392968757\n",
      "Epoch [72/150], Loss: 0.19316925524004425\n",
      "Epoch [73/150], Loss: 0.19172215393390313\n",
      "Epoch [74/150], Loss: 0.19043137491397405\n",
      "Epoch [75/150], Loss: 0.18931166583577094\n",
      "Epoch [76/150], Loss: 0.1879180087503628\n",
      "Epoch [77/150], Loss: 0.1870067989337258\n",
      "Epoch [78/150], Loss: 0.18610828185173645\n",
      "Epoch [79/150], Loss: 0.18497234650400546\n",
      "Epoch [80/150], Loss: 0.18412943037519774\n",
      "Epoch [81/150], Loss: 0.1827796455625406\n",
      "Epoch [82/150], Loss: 0.1818467325012025\n",
      "Epoch [83/150], Loss: 0.1809954980200952\n",
      "Epoch [84/150], Loss: 0.17980164673375354\n",
      "Epoch [85/150], Loss: 0.17898088708424864\n",
      "Epoch [86/150], Loss: 0.1780781712970541\n",
      "Epoch [87/150], Loss: 0.17700887274908989\n",
      "Epoch [88/150], Loss: 0.17657928934272302\n",
      "Epoch [89/150], Loss: 0.17507963645319494\n",
      "Epoch [90/150], Loss: 0.1744195508582925\n",
      "Epoch [91/150], Loss: 0.17321169864706462\n",
      "Epoch [92/150], Loss: 0.1727099993956411\n",
      "Epoch [93/150], Loss: 0.17154189417491822\n",
      "Epoch [94/150], Loss: 0.17085533611088372\n",
      "Epoch [95/150], Loss: 0.1699654886412997\n",
      "Epoch [96/150], Loss: 0.16918859111710724\n",
      "Epoch [97/150], Loss: 0.1682414126531124\n",
      "Epoch [98/150], Loss: 0.16761743075022725\n",
      "Epoch [99/150], Loss: 0.16668226160425303\n",
      "Epoch [100/150], Loss: 0.16554410049081586\n",
      "Epoch [101/150], Loss: 0.16507182950995047\n",
      "Epoch [102/150], Loss: 0.16431664805674517\n",
      "Epoch [103/150], Loss: 0.16349816598985734\n",
      "Epoch [104/150], Loss: 0.16258843671994205\n",
      "Epoch [105/150], Loss: 0.16178910777482572\n",
      "Epoch [106/150], Loss: 0.16100383912432395\n",
      "Epoch [107/150], Loss: 0.1602502838265112\n",
      "Epoch [108/150], Loss: 0.15999518252779185\n",
      "Epoch [109/150], Loss: 0.15900111716466683\n",
      "Epoch [110/150], Loss: 0.15856475867147674\n",
      "Epoch [111/150], Loss: 0.15752138386656103\n",
      "Epoch [112/150], Loss: 0.1567104582709532\n",
      "Epoch [113/150], Loss: 0.15630773854654398\n",
      "Epoch [114/150], Loss: 0.15589089811976495\n",
      "Epoch [115/150], Loss: 0.15490963164211521\n",
      "Epoch [116/150], Loss: 0.1544150667084056\n",
      "Epoch [117/150], Loss: 0.1537779362265331\n",
      "Epoch [118/150], Loss: 0.15311347127575817\n",
      "Epoch [119/150], Loss: 0.1525471510294107\n",
      "Epoch [120/150], Loss: 0.15172287110337251\n",
      "Epoch [121/150], Loss: 0.15125708568665625\n",
      "Epoch [122/150], Loss: 0.150593513096998\n",
      "Epoch [123/150], Loss: 0.1496392843586412\n",
      "Epoch [124/150], Loss: 0.1493786769893098\n",
      "Epoch [125/150], Loss: 0.14872896657480061\n",
      "Epoch [126/150], Loss: 0.14814934157838192\n",
      "Epoch [127/150], Loss: 0.14744367769081146\n",
      "Epoch [128/150], Loss: 0.14657322392755304\n",
      "Epoch [129/150], Loss: 0.14656085836596808\n",
      "Epoch [130/150], Loss: 0.14532033085704704\n",
      "Epoch [131/150], Loss: 0.14540330308290625\n",
      "Epoch [132/150], Loss: 0.14460595381390642\n",
      "Epoch [133/150], Loss: 0.1439156864703788\n",
      "Epoch [134/150], Loss: 0.14340703548043288\n",
      "Epoch [135/150], Loss: 0.14264630322732652\n",
      "Epoch [136/150], Loss: 0.142288273870392\n",
      "Epoch [137/150], Loss: 0.1418142416375437\n",
      "Epoch [138/150], Loss: 0.14152947187400422\n",
      "Epoch [139/150], Loss: 0.14085799632230192\n",
      "Epoch [140/150], Loss: 0.14013653375123492\n",
      "Epoch [141/150], Loss: 0.14000674563086554\n",
      "Epoch [142/150], Loss: 0.13952666223507065\n",
      "Epoch [143/150], Loss: 0.13876127938594437\n",
      "Epoch [144/150], Loss: 0.13829575194072094\n",
      "Epoch [145/150], Loss: 0.13804188266397976\n",
      "Epoch [146/150], Loss: 0.13750290603551063\n",
      "Epoch [147/150], Loss: 0.13694991163529147\n",
      "Epoch [148/150], Loss: 0.13655440535394883\n",
      "Epoch [149/150], Loss: 0.13597810032418542\n",
      "Epoch [150/150], Loss: 0.1354720695563398\n",
      "Epoch 150 Accuracy = 92.57%, Loss = 0.0155\n",
      "Epoch [1/25], Loss: 2.12096114359765\n",
      "Epoch [2/25], Loss: 0.8645486692929796\n",
      "Epoch [3/25], Loss: 0.6692888023186631\n",
      "Epoch [4/25], Loss: 0.577651613919142\n",
      "Epoch [5/25], Loss: 0.5191622074472252\n",
      "Epoch [6/25], Loss: 0.48053508083561125\n",
      "Epoch [7/25], Loss: 0.44772650400522007\n",
      "Epoch [8/25], Loss: 0.4256218364693535\n",
      "Epoch [9/25], Loss: 0.4071648078871658\n",
      "Epoch [10/25], Loss: 0.3917500386286993\n",
      "Epoch [11/25], Loss: 0.3766246501610149\n",
      "Epoch [12/25], Loss: 0.3641768730734087\n",
      "Epoch [13/25], Loss: 0.35270430434743566\n",
      "Epoch [14/25], Loss: 0.3425783199922492\n",
      "Epoch [15/25], Loss: 0.33372392907653314\n",
      "Epoch [16/25], Loss: 0.3257361972404178\n",
      "Epoch [17/25], Loss: 0.31761986762902233\n",
      "Epoch [18/25], Loss: 0.3104932102961854\n",
      "Epoch [19/25], Loss: 0.303792445402476\n",
      "Epoch [20/25], Loss: 0.29779548246774357\n",
      "Epoch [21/25], Loss: 0.29166698780298855\n",
      "Epoch [22/25], Loss: 0.2861867946336279\n",
      "Epoch [23/25], Loss: 0.28146601293057516\n",
      "Epoch [24/25], Loss: 0.27648987417753473\n",
      "Epoch [25/25], Loss: 0.2713536970104712\n",
      "Epoch 25 Accuracy = 89.81%, Loss = 0.0457\n",
      "Epoch [1/50], Loss: 2.1765672617265954\n",
      "Epoch [2/50], Loss: 0.8918368396561127\n",
      "Epoch [3/50], Loss: 0.6864118955731683\n",
      "Epoch [4/50], Loss: 0.5910165609041385\n",
      "Epoch [5/50], Loss: 0.5245893775790464\n",
      "Epoch [6/50], Loss: 0.4796751301982828\n",
      "Epoch [7/50], Loss: 0.4465172993450348\n",
      "Epoch [8/50], Loss: 0.4209914325994905\n",
      "Epoch [9/50], Loss: 0.39981849408312703\n",
      "Epoch [10/50], Loss: 0.38250736269564367\n",
      "Epoch [11/50], Loss: 0.36812753982492724\n",
      "Epoch [12/50], Loss: 0.3545201077022745\n",
      "Epoch [13/50], Loss: 0.34309774615526356\n",
      "Epoch [14/50], Loss: 0.3338141693843063\n",
      "Epoch [15/50], Loss: 0.32250429937852704\n",
      "Epoch [16/50], Loss: 0.3136543022290377\n",
      "Epoch [17/50], Loss: 0.305930955309382\n",
      "Epoch [18/50], Loss: 0.29886948991805545\n",
      "Epoch [19/50], Loss: 0.2921110564912863\n",
      "Epoch [20/50], Loss: 0.28619179744731327\n",
      "Epoch [21/50], Loss: 0.2797218177508718\n",
      "Epoch [22/50], Loss: 0.2744045267975501\n",
      "Epoch [23/50], Loss: 0.27033846162932845\n",
      "Epoch [24/50], Loss: 0.2651522731044679\n",
      "Epoch [25/50], Loss: 0.26071004354344524\n",
      "Epoch [26/50], Loss: 0.25640801712703737\n",
      "Epoch [27/50], Loss: 0.25278656735484645\n",
      "Epoch [28/50], Loss: 0.2493223790785414\n",
      "Epoch [29/50], Loss: 0.24530746190057834\n",
      "Epoch [30/50], Loss: 0.24256476711540018\n",
      "Epoch [31/50], Loss: 0.2391444908202393\n",
      "Epoch [32/50], Loss: 0.236315470789923\n",
      "Epoch [33/50], Loss: 0.23335928112064722\n",
      "Epoch [34/50], Loss: 0.230146462207078\n",
      "Epoch [35/50], Loss: 0.22767178820166736\n",
      "Epoch [36/50], Loss: 0.22493202036203971\n",
      "Epoch [37/50], Loss: 0.2224840341268767\n",
      "Epoch [38/50], Loss: 0.21949541668225234\n",
      "Epoch [39/50], Loss: 0.21763229414560678\n",
      "Epoch [40/50], Loss: 0.21488946172833676\n",
      "Epoch [41/50], Loss: 0.21275417950886186\n",
      "Epoch [42/50], Loss: 0.21045086746290326\n",
      "Epoch [43/50], Loss: 0.2085065852208354\n",
      "Epoch [44/50], Loss: 0.20658237788756378\n",
      "Epoch [45/50], Loss: 0.20449071019051673\n",
      "Epoch [46/50], Loss: 0.20213602646812798\n",
      "Epoch [47/50], Loss: 0.2005571750412928\n",
      "Epoch [48/50], Loss: 0.19843028086450068\n",
      "Epoch [49/50], Loss: 0.1967786760234012\n",
      "Epoch [50/50], Loss: 0.19498560956314517\n",
      "Epoch 50 Accuracy = 91.09%, Loss = 0.1316\n",
      "Epoch [1/100], Loss: 2.2320679004148114\n",
      "Epoch [2/100], Loss: 0.9352835046076216\n",
      "Epoch [3/100], Loss: 0.7237568277095755\n",
      "Epoch [4/100], Loss: 0.6214851888737175\n",
      "Epoch [5/100], Loss: 0.558675039990029\n",
      "Epoch [6/100], Loss: 0.5163589645664518\n",
      "Epoch [7/100], Loss: 0.4828931091090975\n",
      "Epoch [8/100], Loss: 0.45628459578581776\n",
      "Epoch [9/100], Loss: 0.4344115843285496\n",
      "Epoch [10/100], Loss: 0.41863129593734627\n",
      "Epoch [11/100], Loss: 0.40204114467623486\n",
      "Epoch [12/100], Loss: 0.3886202379688621\n",
      "Epoch [13/100], Loss: 0.37602703679779853\n",
      "Epoch [14/100], Loss: 0.36590890850204355\n",
      "Epoch [15/100], Loss: 0.3572213042273652\n",
      "Epoch [16/100], Loss: 0.34751749370188917\n",
      "Epoch [17/100], Loss: 0.33915414703179464\n",
      "Epoch [18/100], Loss: 0.33148340534213155\n",
      "Epoch [19/100], Loss: 0.32428119048107573\n",
      "Epoch [20/100], Loss: 0.31869986111969534\n",
      "Epoch [21/100], Loss: 0.3127654596081314\n",
      "Epoch [22/100], Loss: 0.3066059666345051\n",
      "Epoch [23/100], Loss: 0.3010837923899526\n",
      "Epoch [24/100], Loss: 0.29606478542628856\n",
      "Epoch [25/100], Loss: 0.29172158952239746\n",
      "Epoch [26/100], Loss: 0.28669974840055995\n",
      "Epoch [27/100], Loss: 0.2829999429792515\n",
      "Epoch [28/100], Loss: 0.27856550862345225\n",
      "Epoch [29/100], Loss: 0.2749777544405467\n",
      "Epoch [30/100], Loss: 0.27122199899699384\n",
      "Epoch [31/100], Loss: 0.26781454631135176\n",
      "Epoch [32/100], Loss: 0.264699346352485\n",
      "Epoch [33/100], Loss: 0.2609195892434412\n",
      "Epoch [34/100], Loss: 0.257759355195992\n",
      "Epoch [35/100], Loss: 0.254528181021257\n",
      "Epoch [36/100], Loss: 0.25182465969759504\n",
      "Epoch [37/100], Loss: 0.2486790751266235\n",
      "Epoch [38/100], Loss: 0.24551734239126866\n",
      "Epoch [39/100], Loss: 0.2430658105831826\n",
      "Epoch [40/100], Loss: 0.2409003531370351\n",
      "Epoch [41/100], Loss: 0.2381175534472762\n",
      "Epoch [42/100], Loss: 0.23564697060811643\n",
      "Epoch [43/100], Loss: 0.23318387568633384\n",
      "Epoch [44/100], Loss: 0.23070101948744073\n",
      "Epoch [45/100], Loss: 0.22895317343092755\n",
      "Epoch [46/100], Loss: 0.22610734129392465\n",
      "Epoch [47/100], Loss: 0.2241698813541443\n",
      "Epoch [48/100], Loss: 0.2221854569076289\n",
      "Epoch [49/100], Loss: 0.22045400276227156\n",
      "Epoch [50/100], Loss: 0.21847974401826892\n",
      "Epoch [51/100], Loss: 0.21628851348441094\n",
      "Epoch [52/100], Loss: 0.21481101985479473\n",
      "Epoch [53/100], Loss: 0.21260125921069023\n",
      "Epoch [54/100], Loss: 0.21073859991205973\n",
      "Epoch [55/100], Loss: 0.20933926689613144\n",
      "Epoch [56/100], Loss: 0.20733584772554847\n",
      "Epoch [57/100], Loss: 0.20618418250685014\n",
      "Epoch [58/100], Loss: 0.2041577460944051\n",
      "Epoch [59/100], Loss: 0.20275784112005688\n",
      "Epoch [60/100], Loss: 0.2014281767118373\n",
      "Epoch [61/100], Loss: 0.19978333831083728\n",
      "Epoch [62/100], Loss: 0.19808850013800353\n",
      "Epoch [63/100], Loss: 0.19688704977950935\n",
      "Epoch [64/100], Loss: 0.19522305374218074\n",
      "Epoch [65/100], Loss: 0.19365993824923255\n",
      "Epoch [66/100], Loss: 0.19225671565097097\n",
      "Epoch [67/100], Loss: 0.19124358781515913\n",
      "Epoch [68/100], Loss: 0.18966108487203018\n",
      "Epoch [69/100], Loss: 0.1883890952860044\n",
      "Epoch [70/100], Loss: 0.18735013361948466\n",
      "Epoch [71/100], Loss: 0.1857017985813242\n",
      "Epoch [72/100], Loss: 0.18481205876522774\n",
      "Epoch [73/100], Loss: 0.18377947006799514\n",
      "Epoch [74/100], Loss: 0.18245895723177818\n",
      "Epoch [75/100], Loss: 0.18151177023310447\n",
      "Epoch [76/100], Loss: 0.18019440146008855\n",
      "Epoch [77/100], Loss: 0.1791773903616413\n",
      "Epoch [78/100], Loss: 0.17821994194844348\n",
      "Epoch [79/100], Loss: 0.17714265903564713\n",
      "Epoch [80/100], Loss: 0.17594733785412972\n",
      "Epoch [81/100], Loss: 0.17486610204633327\n",
      "Epoch [82/100], Loss: 0.17410904840003544\n",
      "Epoch [83/100], Loss: 0.17309238076068384\n",
      "Epoch [84/100], Loss: 0.17213428669643568\n",
      "Epoch [85/100], Loss: 0.1711934140817078\n",
      "Epoch [86/100], Loss: 0.17027180675499645\n",
      "Epoch [87/100], Loss: 0.16926653855441934\n",
      "Epoch [88/100], Loss: 0.16812176385124622\n",
      "Epoch [89/100], Loss: 0.16741913121264468\n",
      "Epoch [90/100], Loss: 0.1664896011816624\n",
      "Epoch [91/100], Loss: 0.1656215012560812\n",
      "Epoch [92/100], Loss: 0.1648278720198626\n",
      "Epoch [93/100], Loss: 0.16364525338362243\n",
      "Epoch [94/100], Loss: 0.16328242118335523\n",
      "Epoch [95/100], Loss: 0.16262401679709243\n",
      "Epoch [96/100], Loss: 0.1610805734906365\n",
      "Epoch [97/100], Loss: 0.16080963471365492\n",
      "Epoch [98/100], Loss: 0.1598915853582827\n",
      "Epoch [99/100], Loss: 0.15912724965072994\n",
      "Epoch [100/100], Loss: 0.15840439886771007\n",
      "Epoch 100 Accuracy = 92.02%, Loss = 0.2347\n",
      "Epoch [1/150], Loss: 2.3109320870016234\n",
      "Epoch [2/150], Loss: 0.8904395723335425\n",
      "Epoch [3/150], Loss: 0.6837983098139521\n",
      "Epoch [4/150], Loss: 0.5768563385246864\n",
      "Epoch [5/150], Loss: 0.5172910093202566\n",
      "Epoch [6/150], Loss: 0.47239774189450934\n",
      "Epoch [7/150], Loss: 0.442082735391877\n",
      "Epoch [8/150], Loss: 0.41724363824515603\n",
      "Epoch [9/150], Loss: 0.39746684149318995\n",
      "Epoch [10/150], Loss: 0.3807174931188347\n",
      "Epoch [11/150], Loss: 0.3659803381954941\n",
      "Epoch [12/150], Loss: 0.3530758301794801\n",
      "Epoch [13/150], Loss: 0.34048071269275776\n",
      "Epoch [14/150], Loss: 0.33133828386536335\n",
      "Epoch [15/150], Loss: 0.32219634834880706\n",
      "Epoch [16/150], Loss: 0.31345975829695816\n",
      "Epoch [17/150], Loss: 0.30633934772150434\n",
      "Epoch [18/150], Loss: 0.29841091023063443\n",
      "Epoch [19/150], Loss: 0.29247204561036777\n",
      "Epoch [20/150], Loss: 0.28667582968929006\n",
      "Epoch [21/150], Loss: 0.28118892229441556\n",
      "Epoch [22/150], Loss: 0.27608324113478494\n",
      "Epoch [23/150], Loss: 0.2706623759983146\n",
      "Epoch [24/150], Loss: 0.26579747631850964\n",
      "Epoch [25/150], Loss: 0.2613714518385338\n",
      "Epoch [26/150], Loss: 0.2571507174413806\n",
      "Epoch [27/150], Loss: 0.25345489230266927\n",
      "Epoch [28/150], Loss: 0.2490465995326425\n",
      "Epoch [29/150], Loss: 0.24545240572384017\n",
      "Epoch [30/150], Loss: 0.24161566668160958\n",
      "Epoch [31/150], Loss: 0.23834546304789062\n",
      "Epoch [32/150], Loss: 0.23447176594275515\n",
      "Epoch [33/150], Loss: 0.2317907260232799\n",
      "Epoch [34/150], Loss: 0.22848728125032114\n",
      "Epoch [35/150], Loss: 0.22590949335294622\n",
      "Epoch [36/150], Loss: 0.2233998820129782\n",
      "Epoch [37/150], Loss: 0.21980586472083816\n",
      "Epoch [38/150], Loss: 0.2174735961605426\n",
      "Epoch [39/150], Loss: 0.214887156957353\n",
      "Epoch [40/150], Loss: 0.21210196777052867\n",
      "Epoch [41/150], Loss: 0.2098165280672838\n",
      "Epoch [42/150], Loss: 0.20718063962872837\n",
      "Epoch [43/150], Loss: 0.20535101261406574\n",
      "Epoch [44/150], Loss: 0.20283181571398504\n",
      "Epoch [45/150], Loss: 0.20105472560155127\n",
      "Epoch [46/150], Loss: 0.19862173024832736\n",
      "Epoch [47/150], Loss: 0.19654780230667288\n",
      "Epoch [48/150], Loss: 0.19441364824959115\n",
      "Epoch [49/150], Loss: 0.19248312524093975\n",
      "Epoch [50/150], Loss: 0.19062702273777782\n",
      "Epoch [51/150], Loss: 0.18883115370558032\n",
      "Epoch [52/150], Loss: 0.18739691775160222\n",
      "Epoch [53/150], Loss: 0.1855448712684835\n",
      "Epoch [54/150], Loss: 0.1840400619127904\n",
      "Epoch [55/150], Loss: 0.1818867991418083\n",
      "Epoch [56/150], Loss: 0.1803799393645507\n",
      "Epoch [57/150], Loss: 0.17878002919302283\n",
      "Epoch [58/150], Loss: 0.17725455589524547\n",
      "Epoch [59/150], Loss: 0.17584658050046226\n",
      "Epoch [60/150], Loss: 0.17424537241223637\n",
      "Epoch [61/150], Loss: 0.17287040238129944\n",
      "Epoch [62/150], Loss: 0.17150683258662078\n",
      "Epoch [63/150], Loss: 0.1700653815629145\n",
      "Epoch [64/150], Loss: 0.16843898570474752\n",
      "Epoch [65/150], Loss: 0.1675184760385746\n",
      "Epoch [66/150], Loss: 0.16624496369918537\n",
      "Epoch [67/150], Loss: 0.16469974235556825\n",
      "Epoch [68/150], Loss: 0.16378856486296475\n",
      "Epoch [69/150], Loss: 0.16280379570457928\n",
      "Epoch [70/150], Loss: 0.16154510533965852\n",
      "Epoch [71/150], Loss: 0.16017446212755748\n",
      "Epoch [72/150], Loss: 0.15937512302050405\n",
      "Epoch [73/150], Loss: 0.15797104243305513\n",
      "Epoch [74/150], Loss: 0.15654518114386884\n",
      "Epoch [75/150], Loss: 0.15530486066008356\n",
      "Epoch [76/150], Loss: 0.15454644263205894\n",
      "Epoch [77/150], Loss: 0.1534964590744882\n",
      "Epoch [78/150], Loss: 0.15269744964353352\n",
      "Epoch [79/150], Loss: 0.15153286198929225\n",
      "Epoch [80/150], Loss: 0.15051929252581128\n",
      "Epoch [81/150], Loss: 0.14963714947502982\n",
      "Epoch [82/150], Loss: 0.14852345852630486\n",
      "Epoch [83/150], Loss: 0.14810373647706243\n",
      "Epoch [84/150], Loss: 0.14673602286388632\n",
      "Epoch [85/150], Loss: 0.14587263078442386\n",
      "Epoch [86/150], Loss: 0.14502803829088226\n",
      "Epoch [87/150], Loss: 0.14441702628394706\n",
      "Epoch [88/150], Loss: 0.1436143737227661\n",
      "Epoch [89/150], Loss: 0.14251570377907288\n",
      "Epoch [90/150], Loss: 0.14177690189577213\n",
      "Epoch [91/150], Loss: 0.1411578604230502\n",
      "Epoch [92/150], Loss: 0.14000091674595752\n",
      "Epoch [93/150], Loss: 0.13926850295025117\n",
      "Epoch [94/150], Loss: 0.13876529195647164\n",
      "Epoch [95/150], Loss: 0.13762568406477416\n",
      "Epoch [96/150], Loss: 0.13703676564454023\n",
      "Epoch [97/150], Loss: 0.13639134502583572\n",
      "Epoch [98/150], Loss: 0.13564092350949067\n",
      "Epoch [99/150], Loss: 0.1344622886654009\n",
      "Epoch [100/150], Loss: 0.13407885342310086\n",
      "Epoch [101/150], Loss: 0.13332685505065214\n",
      "Epoch [102/150], Loss: 0.13256734993334976\n",
      "Epoch [103/150], Loss: 0.13208081519819098\n",
      "Epoch [104/150], Loss: 0.13134232947352575\n",
      "Epoch [105/150], Loss: 0.13081866650138302\n",
      "Epoch [106/150], Loss: 0.13016422535588207\n",
      "Epoch [107/150], Loss: 0.12966397347518555\n",
      "Epoch [108/150], Loss: 0.1284415250191402\n",
      "Epoch [109/150], Loss: 0.12799732887092735\n",
      "Epoch [110/150], Loss: 0.1275499488201458\n",
      "Epoch [111/150], Loss: 0.1267259763234906\n",
      "Epoch [112/150], Loss: 0.12617993096031813\n",
      "Epoch [113/150], Loss: 0.125580845817065\n",
      "Epoch [114/150], Loss: 0.12487034591495709\n",
      "Epoch [115/150], Loss: 0.1241749100493483\n",
      "Epoch [116/150], Loss: 0.12347091903563705\n",
      "Epoch [117/150], Loss: 0.12302757720249549\n",
      "Epoch [118/150], Loss: 0.1224072406965303\n",
      "Epoch [119/150], Loss: 0.12184714870331663\n",
      "Epoch [120/150], Loss: 0.12144207289866366\n",
      "Epoch [121/150], Loss: 0.12072402883532778\n",
      "Epoch [122/150], Loss: 0.1201012722960877\n",
      "Epoch [123/150], Loss: 0.11951907472882886\n",
      "Epoch [124/150], Loss: 0.1191628318013536\n",
      "Epoch [125/150], Loss: 0.11858828570427431\n",
      "Epoch [126/150], Loss: 0.11822444060299434\n",
      "Epoch [127/150], Loss: 0.11749334590737513\n",
      "Epoch [128/150], Loss: 0.11705030612077766\n",
      "Epoch [129/150], Loss: 0.11634878888308837\n",
      "Epoch [130/150], Loss: 0.11575763000521207\n",
      "Epoch [131/150], Loss: 0.11512538953440768\n",
      "Epoch [132/150], Loss: 0.11460825870187545\n",
      "Epoch [133/150], Loss: 0.11446196005534875\n",
      "Epoch [134/150], Loss: 0.11378973688422168\n",
      "Epoch [135/150], Loss: 0.11323127284744987\n",
      "Epoch [136/150], Loss: 0.1127338756014918\n",
      "Epoch [137/150], Loss: 0.11234237139845694\n",
      "Epoch [138/150], Loss: 0.11197926741771395\n",
      "Epoch [139/150], Loss: 0.11121009337443077\n",
      "Epoch [140/150], Loss: 0.11108253265475408\n",
      "Epoch [141/150], Loss: 0.11067906949880368\n",
      "Epoch [142/150], Loss: 0.1100815551536604\n",
      "Epoch [143/150], Loss: 0.10951203675191937\n",
      "Epoch [144/150], Loss: 0.10920590952238247\n",
      "Epoch [145/150], Loss: 0.10881253693473264\n",
      "Epoch [146/150], Loss: 0.10841841184531222\n",
      "Epoch [147/150], Loss: 0.10788607348087922\n",
      "Epoch [148/150], Loss: 0.10722947727987533\n",
      "Epoch [149/150], Loss: 0.10686850031611782\n",
      "Epoch [150/150], Loss: 0.10655324909942161\n",
      "Epoch 150 Accuracy = 92.52%, Loss = 0.0032\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]\n",
    "accuracies_epoch = []\n",
    "accuracies_hidden = []\n",
    "\n",
    "# Define the model architecture\n",
    "input_size = 784\n",
    "output_size = len(trainloader.dataset.classes)\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    accuracies_epoch_for_hidden = []\n",
    "    for epochs in epochs_list:\n",
    "        # Initialize weights with random values\n",
    "        w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "        w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_loss = 0.0\n",
    "            for images, labels in trainloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                # Forward pass\n",
    "                h = images.mm(w1)\n",
    "                h_tan = h.tanh()\n",
    "                y_pred = h_tan.mm(w2)\n",
    "                y_pred_sf = y_pred.softmax(dim=1)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                # Backpropagation\n",
    "                grad_y_pred = y_pred_sf.clone()\n",
    "                grad_y_pred[range(images.shape[0]), labels] -= 1\n",
    "                grad_w2 = h_tan.t().mm(grad_y_pred)\n",
    "                grad_h_tan = grad_y_pred.mm(w2.t())\n",
    "                grad_h = grad_h_tan * (1 - h_tan**2)\n",
    "                grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                # Update weights manually\n",
    "                with torch.no_grad():\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(trainloader)}')\n",
    "\n",
    "        # Evaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                h_tan = x.mm(w1).tanh()\n",
    "                y_pred = h_tan.mm(w2)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                total += y.size(0)\n",
    "                correct += (predictions == y).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        accuracies_epoch_for_hidden.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy = {accuracy:.2f}%, Loss = {loss:.4f}\")\n",
    "\n",
    "    accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "\n",
    "# Plot the accuracy against the number of epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    plt.plot(epochs_list, accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Epochs for Different Hidden Layer Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy against the number of hidden layers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, epoch in enumerate(epochs_list):\n",
    "    plt.plot(hidden_sizes, [accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Hidden Layers for Different Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppBHlM08CZDw"
   },
   "source": [
    "Below is the code for relu activation function with mini-batch gradient - batch size is 10. Epochs are 25, 50, 100, 150 and Hidden layer neurons count as  25, 50, 100, 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3ftSnBcabAs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: inf\n",
      "Epoch [2/25], Loss: 1.4098715389172236\n",
      "Epoch [3/25], Loss: 1.1480209658183158\n",
      "Epoch [4/25], Loss: 0.9966049946248531\n",
      "Epoch [5/25], Loss: 0.8966858030892909\n",
      "Epoch [6/25], Loss: 0.8183965977939467\n",
      "Epoch [7/25], Loss: 0.7548166111735627\n",
      "Epoch [8/25], Loss: 0.7039645435269922\n",
      "Epoch [9/25], Loss: 0.6680460308293501\n",
      "Epoch [10/25], Loss: 0.6404238665907954\n",
      "Epoch [11/25], Loss: 0.6162175307154345\n",
      "Epoch [12/25], Loss: 0.5998404141202724\n",
      "Epoch [13/25], Loss: 0.5849924296593139\n",
      "Epoch [14/25], Loss: 0.5694586518509314\n",
      "Epoch [15/25], Loss: 0.5575656891916878\n",
      "Epoch [16/25], Loss: 0.5472234300557369\n",
      "Epoch [17/25], Loss: 0.5340747766346515\n",
      "Epoch [18/25], Loss: 0.5267505083676273\n",
      "Epoch [19/25], Loss: 0.5190352385415075\n",
      "Epoch [20/25], Loss: 0.5104343450952632\n",
      "Epoch [21/25], Loss: 0.5036470326837152\n",
      "Epoch [22/25], Loss: 0.4984143994964349\n",
      "Epoch [23/25], Loss: 0.49160237882069\n",
      "Epoch [24/25], Loss: 0.4881798222196521\n",
      "Epoch [25/25], Loss: 0.4797189619791073\n",
      "Epoch 25 Accuracy = 87.27%, Loss = 0.3236\n",
      "Epoch [1/50], Loss: inf\n",
      "Epoch [2/50], Loss: 1.314289837139348\n",
      "Epoch [3/50], Loss: 1.0852745420572658\n",
      "Epoch [4/50], Loss: 0.9616601722358415\n",
      "Epoch [5/50], Loss: 0.8780213647450631\n",
      "Epoch [6/50], Loss: 0.8046563328808795\n",
      "Epoch [7/50], Loss: 0.756431721037409\n",
      "Epoch [8/50], Loss: 0.7101516530386482\n",
      "Epoch [9/50], Loss: 0.6777748578305667\n",
      "Epoch [10/50], Loss: 0.6497563246356634\n",
      "Epoch [11/50], Loss: 0.627306846916986\n",
      "Epoch [12/50], Loss: 0.6088062283863158\n",
      "Epoch [13/50], Loss: 0.5917434422452158\n",
      "Epoch [14/50], Loss: 0.5738128094518712\n",
      "Epoch [15/50], Loss: 0.5600931421682084\n",
      "Epoch [16/50], Loss: 0.545471664738725\n",
      "Epoch [17/50], Loss: 0.5350258981043007\n",
      "Epoch [18/50], Loss: 0.525708392665023\n",
      "Epoch [19/50], Loss: 0.515064938296952\n",
      "Epoch [20/50], Loss: 0.5061021987108203\n",
      "Epoch [21/50], Loss: 0.49758804279583274\n",
      "Epoch [22/50], Loss: 0.4912245149263181\n",
      "Epoch [23/50], Loss: 0.4828285735799776\n",
      "Epoch [24/50], Loss: 0.4750563027674798\n",
      "Epoch [25/50], Loss: 0.46916841303937445\n",
      "Epoch [26/50], Loss: 0.4639504343414446\n",
      "Epoch [27/50], Loss: 0.4567933700360979\n",
      "Epoch [28/50], Loss: 0.45202834803572234\n",
      "Epoch [29/50], Loss: 0.44890445640539595\n",
      "Epoch [30/50], Loss: 0.4437488428414799\n",
      "Epoch [31/50], Loss: 0.43790930320873545\n",
      "Epoch [32/50], Loss: 0.4330071012938085\n",
      "Epoch [33/50], Loss: 0.4295692134816976\n",
      "Epoch [34/50], Loss: 0.4226843721392021\n",
      "Epoch [35/50], Loss: 0.4215107808500761\n",
      "Epoch [36/50], Loss: 0.4170790199664577\n",
      "Epoch [37/50], Loss: 0.4122678197362305\n",
      "Epoch [38/50], Loss: 0.40836875592319605\n",
      "Epoch [39/50], Loss: 0.40342465290386464\n",
      "Epoch [40/50], Loss: 0.4001207697032951\n",
      "Epoch [41/50], Loss: 0.39732186472043396\n",
      "Epoch [42/50], Loss: 0.39462474925872326\n",
      "Epoch [43/50], Loss: 0.3903620087817156\n",
      "Epoch [44/50], Loss: 0.387424906810862\n",
      "Epoch [45/50], Loss: 0.3849055269426123\n",
      "Epoch [46/50], Loss: 0.38261844938686895\n",
      "Epoch [47/50], Loss: 0.38049067690758964\n",
      "Epoch [48/50], Loss: 0.376090807669796\n",
      "Epoch [49/50], Loss: 0.3725129461132844\n",
      "Epoch [50/50], Loss: 0.3716921710623816\n",
      "Epoch 50 Accuracy = 87.42%, Loss = 0.5637\n",
      "Epoch [1/100], Loss: inf\n",
      "Epoch [2/100], Loss: 1.7157626987695693\n",
      "Epoch [3/100], Loss: 1.4486507309377195\n",
      "Epoch [4/100], Loss: 1.2837681374326348\n",
      "Epoch [5/100], Loss: 1.1734033782718083\n",
      "Epoch [6/100], Loss: 1.059424502034982\n",
      "Epoch [7/100], Loss: 0.9709810878131538\n",
      "Epoch [8/100], Loss: 0.9063141080215573\n",
      "Epoch [9/100], Loss: 0.8369325628280639\n",
      "Epoch [10/100], Loss: 0.7715275950003415\n",
      "Epoch [11/100], Loss: 0.7201548306738648\n",
      "Epoch [12/100], Loss: 0.6740672477382856\n",
      "Epoch [13/100], Loss: 0.6409102925978756\n",
      "Epoch [14/100], Loss: 0.6142464475137337\n",
      "Epoch [15/100], Loss: 0.5940720096733421\n",
      "Epoch [16/100], Loss: 0.5738268669306611\n",
      "Epoch [17/100], Loss: 0.5612376919497425\n",
      "Epoch [18/100], Loss: 0.5486970647680574\n",
      "Epoch [19/100], Loss: 0.53760562805001\n",
      "Epoch [20/100], Loss: 0.5270957204067769\n",
      "Epoch [21/100], Loss: 0.5170887257063296\n",
      "Epoch [22/100], Loss: 0.5089315453176386\n",
      "Epoch [23/100], Loss: 0.5030965759552395\n",
      "Epoch [24/100], Loss: 0.4950436773626134\n",
      "Epoch [25/100], Loss: 0.48963162195472976\n",
      "Epoch [26/100], Loss: 0.4817926487343696\n",
      "Epoch [27/100], Loss: 0.4764180805992801\n",
      "Epoch [28/100], Loss: 0.4698094979378705\n",
      "Epoch [29/100], Loss: 0.46436744108912537\n",
      "Epoch [30/100], Loss: 0.45795102219702677\n",
      "Epoch [31/100], Loss: 0.45422334922128355\n",
      "Epoch [32/100], Loss: 0.44874202136749713\n",
      "Epoch [33/100], Loss: 0.44195696954006175\n",
      "Epoch [34/100], Loss: 0.43637246113612005\n",
      "Epoch [35/100], Loss: 0.43164232567193295\n",
      "Epoch [36/100], Loss: 0.4279650748013907\n",
      "Epoch [37/100], Loss: 0.4221621557445809\n",
      "Epoch [38/100], Loss: 0.42081799969573813\n",
      "Epoch [39/100], Loss: 0.416376481857306\n",
      "Epoch [40/100], Loss: 0.41195159938485204\n",
      "Epoch [41/100], Loss: 0.40760034311345467\n",
      "Epoch [42/100], Loss: 0.4052013096565691\n",
      "Epoch [43/100], Loss: 0.40269421836407854\n",
      "Epoch [44/100], Loss: 0.39759907610489365\n",
      "Epoch [45/100], Loss: 0.3949313068008826\n",
      "Epoch [46/100], Loss: 0.3936691639105945\n",
      "Epoch [47/100], Loss: 0.39083800379598205\n",
      "Epoch [48/100], Loss: 0.3879320600098387\n",
      "Epoch [49/100], Loss: 0.38586520327513185\n",
      "Epoch [50/100], Loss: 0.38219721365269893\n",
      "Epoch [51/100], Loss: 0.38095875233089704\n",
      "Epoch [52/100], Loss: 0.37807404320141846\n",
      "Epoch [53/100], Loss: 0.3752090591280333\n",
      "Epoch [54/100], Loss: 0.3730760543989794\n",
      "Epoch [55/100], Loss: 0.3702519469674638\n",
      "Epoch [56/100], Loss: 0.371067840782421\n",
      "Epoch [57/100], Loss: 0.3678216773161742\n",
      "Epoch [58/100], Loss: 0.3659099541187752\n",
      "Epoch [59/100], Loss: 0.36323126814235\n",
      "Epoch [60/100], Loss: 0.36235407391330227\n",
      "Epoch [61/100], Loss: 0.35956819047480043\n",
      "Epoch [62/100], Loss: 0.35671347808884457\n",
      "Epoch [63/100], Loss: 0.35505978012517636\n",
      "Epoch [64/100], Loss: 0.3532995871034994\n",
      "Epoch [65/100], Loss: 0.35154949927624934\n",
      "Epoch [66/100], Loss: 0.34979886664958515\n",
      "Epoch [67/100], Loss: 0.3486348047074086\n",
      "Epoch [68/100], Loss: 0.3454881681521947\n",
      "Epoch [69/100], Loss: 0.34695620470963573\n",
      "Epoch [70/100], Loss: 0.3443288407252791\n",
      "Epoch [71/100], Loss: 0.34095727277259963\n",
      "Epoch [72/100], Loss: 0.3411185514567963\n",
      "Epoch [73/100], Loss: 0.33954931862597976\n",
      "Epoch [74/100], Loss: 0.33783036656631155\n",
      "Epoch [75/100], Loss: 0.33594541392205673\n",
      "Epoch [76/100], Loss: 0.33476295571285297\n",
      "Epoch [77/100], Loss: 0.3330165425982559\n",
      "Epoch [78/100], Loss: 0.33164611096226143\n",
      "Epoch [79/100], Loss: 0.3299100978313557\n",
      "Epoch [80/100], Loss: 0.32789836009044665\n",
      "Epoch [81/100], Loss: 0.327209480968692\n",
      "Epoch [82/100], Loss: 0.3263831677568766\n",
      "Epoch [83/100], Loss: 0.3263095376290536\n",
      "Epoch [84/100], Loss: 0.32552480955733337\n",
      "Epoch [85/100], Loss: 0.321585775027265\n",
      "Epoch [86/100], Loss: 0.3205726434972215\n",
      "Epoch [87/100], Loss: 0.3189620723328165\n",
      "Epoch [88/100], Loss: 0.3199687263361993\n",
      "Epoch [89/100], Loss: 0.3166841910542377\n",
      "Epoch [90/100], Loss: 0.3173258746291394\n",
      "Epoch [91/100], Loss: 0.31520054887838583\n",
      "Epoch [92/100], Loss: 0.31411904304290267\n",
      "Epoch [93/100], Loss: 0.3133117990954391\n",
      "Epoch [94/100], Loss: 0.3119999541193635\n",
      "Epoch [95/100], Loss: 0.3106322111398137\n",
      "Epoch [96/100], Loss: 0.3095572402367834\n",
      "Epoch [97/100], Loss: 0.30822202134615506\n",
      "Epoch [98/100], Loss: 0.30663701448837916\n",
      "Epoch [99/100], Loss: 0.3073292556493737\n",
      "Epoch [100/100], Loss: 0.30598374165043546\n",
      "Epoch 100 Accuracy = 91.04%, Loss = 0.1862\n",
      "Epoch [1/150], Loss: inf\n",
      "Epoch [2/150], Loss: 1.5208215463459491\n",
      "Epoch [3/150], Loss: 1.297745244200031\n",
      "Epoch [4/150], Loss: 1.1581869359773893\n",
      "Epoch [5/150], Loss: 1.0442754266733925\n",
      "Epoch [6/150], Loss: 0.9570667776875198\n",
      "Epoch [7/150], Loss: 0.8684960829230647\n",
      "Epoch [8/150], Loss: 0.8042437903620303\n",
      "Epoch [9/150], Loss: 0.7544525995692238\n",
      "Epoch [10/150], Loss: 0.7175432458054274\n",
      "Epoch [11/150], Loss: 0.6840864752801136\n",
      "Epoch [12/150], Loss: 0.6566740908172602\n",
      "Epoch [13/150], Loss: 0.6338542089836362\n",
      "Epoch [14/150], Loss: 0.613614850025624\n",
      "Epoch [15/150], Loss: 0.5976870959427518\n",
      "Epoch [16/150], Loss: 0.5815974215849613\n",
      "Epoch [17/150], Loss: 0.5692222640408824\n",
      "Epoch [18/150], Loss: 0.5585061535282682\n",
      "Epoch [19/150], Loss: 0.5489007644255957\n",
      "Epoch [20/150], Loss: 0.5395566941220313\n",
      "Epoch [21/150], Loss: 0.5333587577321256\n",
      "Epoch [22/150], Loss: 0.5260102151030054\n",
      "Epoch [23/150], Loss: 0.5175569151071832\n",
      "Epoch [24/150], Loss: 0.5112681328972492\n",
      "Epoch [25/150], Loss: 0.5056093954186266\n",
      "Epoch [26/150], Loss: 0.5004353515819336\n",
      "Epoch [27/150], Loss: 0.4948818280727913\n",
      "Epoch [28/150], Loss: 0.4904753149936441\n",
      "Epoch [29/150], Loss: 0.4873467428192186\n",
      "Epoch [30/150], Loss: 0.4835673891080854\n",
      "Epoch [31/150], Loss: 0.4801272167197118\n",
      "Epoch [32/150], Loss: 0.4757523447848701\n",
      "Epoch [33/150], Loss: 0.4709140194726642\n",
      "Epoch [34/150], Loss: 0.4671956336305787\n",
      "Epoch [35/150], Loss: 0.4653467417648062\n",
      "Epoch [36/150], Loss: 0.461444304954183\n",
      "Epoch [37/150], Loss: 0.45783878887770696\n",
      "Epoch [38/150], Loss: 0.45376165937430535\n",
      "Epoch [39/150], Loss: 0.4518902004566044\n",
      "Epoch [40/150], Loss: 0.4480572638382825\n",
      "Epoch [41/150], Loss: 0.44587299727865803\n",
      "Epoch [42/150], Loss: 0.4416368534901024\n",
      "Epoch [43/150], Loss: 0.44181941138968495\n",
      "Epoch [44/150], Loss: 0.43896931324286076\n",
      "Epoch [45/150], Loss: 0.4357193534048274\n",
      "Epoch [46/150], Loss: 0.4331236001076177\n",
      "Epoch [47/150], Loss: 0.4305049105658351\n",
      "Epoch [48/150], Loss: 0.427505190280887\n",
      "Epoch [49/150], Loss: 0.42682405666510265\n",
      "Epoch [50/150], Loss: 0.42424596793740055\n",
      "Epoch [51/150], Loss: 0.42080090889971083\n",
      "Epoch [52/150], Loss: 0.41705563772919896\n",
      "Epoch [53/150], Loss: 0.41493414070255435\n",
      "Epoch [54/150], Loss: 0.41423481538662843\n",
      "Epoch [55/150], Loss: 0.4142192363403738\n",
      "Epoch [56/150], Loss: 0.4120126324556768\n",
      "Epoch [57/150], Loss: 0.410048173863596\n",
      "Epoch [58/150], Loss: 0.40810010696334453\n",
      "Epoch [59/150], Loss: 0.40600837316534794\n",
      "Epoch [60/150], Loss: 0.4041898992777181\n",
      "Epoch [61/150], Loss: 0.40285348184841374\n",
      "Epoch [62/150], Loss: 0.3996592433960953\n",
      "Epoch [63/150], Loss: 0.40032075430976694\n",
      "Epoch [64/150], Loss: 0.3970747728953138\n",
      "Epoch [65/150], Loss: 0.3964869179879315\n",
      "Epoch [66/150], Loss: 0.3941690060528539\n",
      "Epoch [67/150], Loss: 0.3928774131689376\n",
      "Epoch [68/150], Loss: 0.3930185600906455\n",
      "Epoch [69/150], Loss: 0.3890339516104044\n",
      "Epoch [70/150], Loss: 0.38962428993330106\n",
      "Epoch [71/150], Loss: 0.38811251834065963\n",
      "Epoch [72/150], Loss: 0.3860329237919844\n",
      "Epoch [73/150], Loss: 0.3867922681038811\n",
      "Epoch [74/150], Loss: 0.38441353750322016\n",
      "Epoch [75/150], Loss: 0.38247320405440405\n",
      "Epoch [76/150], Loss: 0.3811529801626069\n",
      "Epoch [77/150], Loss: 0.38065651733389433\n",
      "Epoch [78/150], Loss: 0.3787040184952008\n",
      "Epoch [79/150], Loss: 0.3773475249336334\n",
      "Epoch [80/150], Loss: 0.3762813226393191\n",
      "Epoch [81/150], Loss: 0.3758730097055668\n",
      "Epoch [82/150], Loss: 0.37564547490902866\n",
      "Epoch [83/150], Loss: 0.37488777747331187\n",
      "Epoch [84/150], Loss: 0.3733348851413854\n",
      "Epoch [85/150], Loss: 0.37139357056030226\n",
      "Epoch [86/150], Loss: 0.3708048314738553\n",
      "Epoch [87/150], Loss: 0.36878679554567984\n",
      "Epoch [88/150], Loss: 0.36787137369439005\n",
      "Epoch [89/150], Loss: 0.36657454445861126\n",
      "Epoch [90/150], Loss: 0.36605306599009785\n",
      "Epoch [91/150], Loss: 0.3640238620543387\n",
      "Epoch [92/150], Loss: 0.3625401155183402\n",
      "Epoch [93/150], Loss: 0.3603805374245276\n",
      "Epoch [94/150], Loss: 0.36157386628794486\n",
      "Epoch [95/150], Loss: 0.3607127628296924\n",
      "Epoch [96/150], Loss: 0.35757448091823607\n",
      "Epoch [97/150], Loss: 0.35691788434318733\n",
      "Epoch [98/150], Loss: 0.35656960448475244\n",
      "Epoch [99/150], Loss: 0.3557664399406252\n",
      "Epoch [100/150], Loss: 0.3547892483282679\n",
      "Epoch [101/150], Loss: 0.35423147658406134\n",
      "Epoch [102/150], Loss: 0.35298954252301096\n",
      "Epoch [103/150], Loss: 0.3519637431143783\n",
      "Epoch [104/150], Loss: 0.350850726077954\n",
      "Epoch [105/150], Loss: 0.3508639265734237\n",
      "Epoch [106/150], Loss: 0.34766190559061944\n",
      "Epoch [107/150], Loss: 0.34812640376264853\n",
      "Epoch [108/150], Loss: 0.3471373340045102\n",
      "Epoch [109/150], Loss: 0.34573193832001803\n",
      "Epoch [110/150], Loss: 0.3449018987964373\n",
      "Epoch [111/150], Loss: 0.3448347701353487\n",
      "Epoch [112/150], Loss: 0.34313132824892334\n",
      "Epoch [113/150], Loss: 0.3430830904503043\n",
      "Epoch [114/150], Loss: 0.34293769702922633\n",
      "Epoch [115/150], Loss: 0.34106127249552326\n",
      "Epoch [116/150], Loss: 0.3394965357245722\n",
      "Epoch [117/150], Loss: 0.33978561514099903\n",
      "Epoch [118/150], Loss: 0.33884326098273354\n",
      "Epoch [119/150], Loss: 0.33612535990336134\n",
      "Epoch [120/150], Loss: 0.3343935252879358\n",
      "Epoch [121/150], Loss: 0.33534114069132676\n",
      "Epoch [122/150], Loss: 0.3343157790102026\n",
      "Epoch [123/150], Loss: 0.33402690599214596\n",
      "Epoch [124/150], Loss: 0.3317419357024288\n",
      "Epoch [125/150], Loss: 0.332644527832473\n",
      "Epoch [126/150], Loss: 0.3314673234784665\n",
      "Epoch [127/150], Loss: 0.3295339814229713\n",
      "Epoch [128/150], Loss: 0.32968978096645635\n",
      "Epoch [129/150], Loss: 0.3285203772248157\n",
      "Epoch [130/150], Loss: 0.3289729682719335\n",
      "Epoch [131/150], Loss: 0.32826102911358856\n",
      "Epoch [132/150], Loss: 0.3260429972386919\n",
      "Epoch [133/150], Loss: 0.3249004557665903\n",
      "Epoch [134/150], Loss: 0.32539488704335723\n",
      "Epoch [135/150], Loss: 0.32440271948982263\n",
      "Epoch [136/150], Loss: 0.32180676883719084\n",
      "Epoch [137/150], Loss: 0.32172753285149036\n",
      "Epoch [138/150], Loss: 0.3217870018631608\n",
      "Epoch [139/150], Loss: 0.32074153396925736\n",
      "Epoch [140/150], Loss: 0.31929517407212793\n",
      "Epoch [141/150], Loss: 0.31743895331921523\n",
      "Epoch [142/150], Loss: 0.3168512489399097\n",
      "Epoch [143/150], Loss: 0.3171150478128499\n",
      "Epoch [144/150], Loss: 0.3158140947301484\n",
      "Epoch [145/150], Loss: 0.3147600901193606\n",
      "Epoch [146/150], Loss: 0.31436666409665487\n",
      "Epoch [147/150], Loss: 0.3114603302178245\n",
      "Epoch [148/150], Loss: 0.31060307648506325\n",
      "Epoch [149/150], Loss: 0.3089761059222316\n",
      "Epoch [150/150], Loss: 0.3094818156355177\n",
      "Epoch 150 Accuracy = 90.99%, Loss = 0.3486\n",
      "Epoch [1/25], Loss: inf\n",
      "Epoch [2/25], Loss: 0.8676360416344057\n",
      "Epoch [3/25], Loss: 0.7305698483060115\n",
      "Epoch [4/25], Loss: 0.6487445636647753\n",
      "Epoch [5/25], Loss: 0.5933337197155536\n",
      "Epoch [6/25], Loss: 0.5512730606973248\n",
      "Epoch [7/25], Loss: 0.5196663674578303\n",
      "Epoch [8/25], Loss: 0.4946709596774696\n",
      "Epoch [9/25], Loss: 0.4711253872476906\n",
      "Epoch [10/25], Loss: 0.4530963105224073\n",
      "Epoch [11/25], Loss: 0.439050386159933\n",
      "Epoch [12/25], Loss: 0.4269770094077491\n",
      "Epoch [13/25], Loss: 0.41394575720400706\n",
      "Epoch [14/25], Loss: 0.40276635508002556\n",
      "Epoch [15/25], Loss: 0.39430879142159636\n",
      "Epoch [16/25], Loss: 0.38597421127713943\n",
      "Epoch [17/25], Loss: 0.37725441973970736\n",
      "Epoch [18/25], Loss: 0.36676980183029084\n",
      "Epoch [19/25], Loss: 0.36189561414724447\n",
      "Epoch [20/25], Loss: 0.3560615798454431\n",
      "Epoch [21/25], Loss: 0.3500367590903479\n",
      "Epoch [22/25], Loss: 0.3429151333521586\n",
      "Epoch [23/25], Loss: 0.33818147774704266\n",
      "Epoch [24/25], Loss: 0.33315093865893625\n",
      "Epoch [25/25], Loss: 0.3273644823186138\n",
      "Epoch 25 Accuracy = 90.12%, Loss = 0.1803\n",
      "Epoch [1/50], Loss: inf\n",
      "Epoch [2/50], Loss: 1.1114825438602518\n",
      "Epoch [3/50], Loss: 0.914483087013786\n",
      "Epoch [4/50], Loss: 0.787553417489243\n",
      "Epoch [5/50], Loss: 0.7105670105603834\n",
      "Epoch [6/50], Loss: 0.6536480446786154\n",
      "Epoch [7/50], Loss: 0.6142494554986091\n",
      "Epoch [8/50], Loss: 0.5819571777121164\n",
      "Epoch [9/50], Loss: 0.5554634857731096\n",
      "Epoch [10/50], Loss: 0.5311286285761355\n",
      "Epoch [11/50], Loss: 0.5137171341724849\n",
      "Epoch [12/50], Loss: 0.4978859380891857\n",
      "Epoch [13/50], Loss: 0.4827840898601765\n",
      "Epoch [14/50], Loss: 0.46857926570360237\n",
      "Epoch [15/50], Loss: 0.4579690790101886\n",
      "Epoch [16/50], Loss: 0.4451056035771811\n",
      "Epoch [17/50], Loss: 0.4347913055716005\n",
      "Epoch [18/50], Loss: 0.423079525458316\n",
      "Epoch [19/50], Loss: 0.41691343861170266\n",
      "Epoch [20/50], Loss: 0.40755410495933997\n",
      "Epoch [21/50], Loss: 0.3996387940522206\n",
      "Epoch [22/50], Loss: 0.3909366959279287\n",
      "Epoch [23/50], Loss: 0.3846984334095226\n",
      "Epoch [24/50], Loss: 0.3785904459664598\n",
      "Epoch [25/50], Loss: 0.37198645123049695\n",
      "Epoch [26/50], Loss: 0.3640193586453873\n",
      "Epoch [27/50], Loss: 0.3599584612916927\n",
      "Epoch [28/50], Loss: 0.3533797129714124\n",
      "Epoch [29/50], Loss: 0.346708889070811\n",
      "Epoch [30/50], Loss: 0.3406920024996119\n",
      "Epoch [31/50], Loss: 0.33576887386317444\n",
      "Epoch [32/50], Loss: 0.33330318098629746\n",
      "Epoch [33/50], Loss: 0.32861872077473286\n",
      "Epoch [34/50], Loss: 0.32517312836423906\n",
      "Epoch [35/50], Loss: 0.3215463923520389\n",
      "Epoch [36/50], Loss: 0.3171526634607095\n",
      "Epoch [37/50], Loss: 0.315429530452219\n",
      "Epoch [38/50], Loss: 0.31125114396802384\n",
      "Epoch [39/50], Loss: 0.30909734446097475\n",
      "Epoch [40/50], Loss: 0.30496502981124407\n",
      "Epoch [41/50], Loss: 0.30255820029297803\n",
      "Epoch [42/50], Loss: 0.29962734744559083\n",
      "Epoch [43/50], Loss: 0.29681465351773173\n",
      "Epoch [44/50], Loss: 0.2940237405983595\n",
      "Epoch [45/50], Loss: 0.2916525699317911\n",
      "Epoch [46/50], Loss: 0.28955393919924005\n",
      "Epoch [47/50], Loss: 0.2869316185254138\n",
      "Epoch [48/50], Loss: 0.283770420584362\n",
      "Epoch [49/50], Loss: 0.2831307162823893\n",
      "Epoch [50/50], Loss: 0.2803812176454448\n",
      "Epoch 50 Accuracy = 91.38%, Loss = 0.1266\n",
      "Epoch [1/100], Loss: inf\n",
      "Epoch [2/100], Loss: 0.8967956236495326\n",
      "Epoch [3/100], Loss: 0.7485180861369396\n",
      "Epoch [4/100], Loss: 0.6639761693306888\n",
      "Epoch [5/100], Loss: 0.6029216801042979\n",
      "Epoch [6/100], Loss: 0.5630309873934214\n",
      "Epoch [7/100], Loss: 0.5287743389769457\n",
      "Epoch [8/100], Loss: 0.5053305998531481\n",
      "Epoch [9/100], Loss: 0.48284216926735823\n",
      "Epoch [10/100], Loss: 0.46537530368713975\n",
      "Epoch [11/100], Loss: 0.452086895479161\n",
      "Epoch [12/100], Loss: 0.43768682237091705\n",
      "Epoch [13/100], Loss: 0.42500146477203815\n",
      "Epoch [14/100], Loss: 0.4137418633621807\n",
      "Epoch [15/100], Loss: 0.4066749697821991\n",
      "Epoch [16/100], Loss: 0.39642890406706527\n",
      "Epoch [17/100], Loss: 0.3890724186359924\n",
      "Epoch [18/100], Loss: 0.3808413508242035\n",
      "Epoch [19/100], Loss: 0.3743063927116649\n",
      "Epoch [20/100], Loss: 0.3689921949384928\n",
      "Epoch [21/100], Loss: 0.36182462138240223\n",
      "Epoch [22/100], Loss: 0.35614195236427865\n",
      "Epoch [23/100], Loss: 0.34926863986366274\n",
      "Epoch [24/100], Loss: 0.3445688190606888\n",
      "Epoch [25/100], Loss: 0.3402299876854134\n",
      "Epoch [26/100], Loss: 0.3342391480107714\n",
      "Epoch [27/100], Loss: 0.3310272615828241\n",
      "Epoch [28/100], Loss: 0.3256627050609483\n",
      "Epoch [29/100], Loss: 0.3213013829952785\n",
      "Epoch [30/100], Loss: 0.3180788300438144\n",
      "Epoch [31/100], Loss: 0.31243035784944856\n",
      "Epoch [32/100], Loss: 0.3090718308952734\n",
      "Epoch [33/100], Loss: 0.30528174066806485\n",
      "Epoch [34/100], Loss: 0.30145287794950615\n",
      "Epoch [35/100], Loss: 0.29763805456874737\n",
      "Epoch [36/100], Loss: 0.29442274737502644\n",
      "Epoch [37/100], Loss: 0.2910659948617589\n",
      "Epoch [38/100], Loss: 0.2891185614078228\n",
      "Epoch [39/100], Loss: 0.2851739135597697\n",
      "Epoch [40/100], Loss: 0.28143455233618686\n",
      "Epoch [41/100], Loss: 0.278848240696471\n",
      "Epoch [42/100], Loss: 0.2758128126943193\n",
      "Epoch [43/100], Loss: 0.27301086606946773\n",
      "Epoch [44/100], Loss: 0.27068154212879986\n",
      "Epoch [45/100], Loss: 0.26931451652082616\n",
      "Epoch [46/100], Loss: 0.26568528367270483\n",
      "Epoch [47/100], Loss: 0.2639319041984951\n",
      "Epoch [48/100], Loss: 0.2583806670748066\n",
      "Epoch [49/100], Loss: 0.258129625996924\n",
      "Epoch [50/100], Loss: 0.2547068901366195\n",
      "Epoch [51/100], Loss: 0.2531113806842477\n",
      "Epoch [52/100], Loss: 0.2508266246198618\n",
      "Epoch [53/100], Loss: 0.2486993930059786\n",
      "Epoch [54/100], Loss: 0.24750801532390082\n",
      "Epoch [55/100], Loss: 0.24410598994808486\n",
      "Epoch [56/100], Loss: 0.24297049244209726\n",
      "Epoch [57/100], Loss: 0.24016119387677706\n",
      "Epoch [58/100], Loss: 0.23774856114112966\n",
      "Epoch [59/100], Loss: 0.23660215055020428\n",
      "Epoch [60/100], Loss: 0.2348854316468302\n",
      "Epoch [61/100], Loss: 0.23210233816091447\n",
      "Epoch [62/100], Loss: 0.23166460068540254\n",
      "Epoch [63/100], Loss: 0.2294146059134849\n",
      "Epoch [64/100], Loss: 0.22802784638238396\n",
      "Epoch [65/100], Loss: 0.22680752640677382\n",
      "Epoch [66/100], Loss: 0.2250604205838657\n",
      "Epoch [67/100], Loss: 0.2235168868972129\n",
      "Epoch [68/100], Loss: 0.2225170036705264\n",
      "Epoch [69/100], Loss: 0.2189762250882753\n",
      "Epoch [70/100], Loss: 0.21821421252785997\n",
      "Epoch [71/100], Loss: 0.21816968292301558\n",
      "Epoch [72/100], Loss: 0.21633055509115728\n",
      "Epoch [73/100], Loss: 0.21328218777105698\n",
      "Epoch [74/100], Loss: 0.21407636263127885\n",
      "Epoch [75/100], Loss: 0.21127280196013454\n",
      "Epoch [76/100], Loss: 0.21109949513386406\n",
      "Epoch [77/100], Loss: 0.2091803046149871\n",
      "Epoch [78/100], Loss: 0.20777397377454024\n",
      "Epoch [79/100], Loss: 0.20730786133169993\n",
      "Epoch [80/100], Loss: 0.2071121881658364\n",
      "Epoch [81/100], Loss: 0.20457516900776923\n",
      "Epoch [82/100], Loss: 0.20408640104746398\n",
      "Epoch [83/100], Loss: 0.20222499255630344\n",
      "Epoch [84/100], Loss: 0.2013627221055188\n",
      "Epoch [85/100], Loss: 0.19887388777432594\n",
      "Epoch [86/100], Loss: 0.1982622676441994\n",
      "Epoch [87/100], Loss: 0.1983242293131431\n",
      "Epoch [88/100], Loss: 0.1968986266937063\n",
      "Epoch [89/100], Loss: 0.1952019210273817\n",
      "Epoch [90/100], Loss: 0.1952126184533469\n",
      "Epoch [91/100], Loss: 0.19307581465353119\n",
      "Epoch [92/100], Loss: 0.19208962316838005\n",
      "Epoch [93/100], Loss: 0.1913031150679526\n",
      "Epoch [94/100], Loss: 0.19098884685219672\n",
      "Epoch [95/100], Loss: 0.18962030602085725\n",
      "Epoch [96/100], Loss: 0.18850933927294075\n",
      "Epoch [97/100], Loss: 0.18696332554760253\n",
      "Epoch [98/100], Loss: 0.1865108514582959\n",
      "Epoch [99/100], Loss: 0.1859050043452077\n",
      "Epoch [100/100], Loss: 0.18555913046802985\n",
      "Epoch 100 Accuracy = 93.79%, Loss = 0.0905\n",
      "Epoch [1/150], Loss: inf\n",
      "Epoch [2/150], Loss: 0.9022701579552764\n",
      "Epoch [3/150], Loss: 0.7450239010855245\n",
      "Epoch [4/150], Loss: 0.6559029175913893\n",
      "Epoch [5/150], Loss: 0.6038636674215085\n",
      "Epoch [6/150], Loss: 0.5682435391147155\n",
      "Epoch [7/150], Loss: 0.5378885939070024\n",
      "Epoch [8/150], Loss: 0.5136260870027278\n",
      "Epoch [9/150], Loss: 0.49579269973481616\n",
      "Epoch [10/150], Loss: 0.47516518001720154\n",
      "Epoch [11/150], Loss: 0.4588178157005847\n",
      "Epoch [12/150], Loss: 0.4422324896509672\n",
      "Epoch [13/150], Loss: 0.4291547692756867\n",
      "Epoch [14/150], Loss: 0.4175878958558509\n",
      "Epoch [15/150], Loss: 0.4073759818696999\n",
      "Epoch [16/150], Loss: 0.4005420922692283\n",
      "Epoch [17/150], Loss: 0.38923890041488146\n",
      "Epoch [18/150], Loss: 0.38356128991944327\n",
      "Epoch [19/150], Loss: 0.37358032438513084\n",
      "Epoch [20/150], Loss: 0.3686116871231934\n",
      "Epoch [21/150], Loss: 0.36107782774143077\n",
      "Epoch [22/150], Loss: 0.35514031465609636\n",
      "Epoch [23/150], Loss: 0.3481722968488466\n",
      "Epoch [24/150], Loss: 0.3437117299133194\n",
      "Epoch [25/150], Loss: 0.3376479785282475\n",
      "Epoch [26/150], Loss: 0.33222264051117234\n",
      "Epoch [27/150], Loss: 0.3288441349199226\n",
      "Epoch [28/150], Loss: 0.3263076081058243\n",
      "Epoch [29/150], Loss: 0.3203407504754238\n",
      "Epoch [30/150], Loss: 0.31692592304499706\n",
      "Epoch [31/150], Loss: 0.3131408178785544\n",
      "Epoch [32/150], Loss: 0.30889301505838135\n",
      "Epoch [33/150], Loss: 0.3051616071759684\n",
      "Epoch [34/150], Loss: 0.30262457159541856\n",
      "Epoch [35/150], Loss: 0.2974140733166423\n",
      "Epoch [36/150], Loss: 0.2948081341407766\n",
      "Epoch [37/150], Loss: 0.29276691860553306\n",
      "Epoch [38/150], Loss: 0.28905991185688373\n",
      "Epoch [39/150], Loss: 0.28695090418676167\n",
      "Epoch [40/150], Loss: 0.2838886567230802\n",
      "Epoch [41/150], Loss: 0.28181706121880656\n",
      "Epoch [42/150], Loss: 0.27992297435870567\n",
      "Epoch [43/150], Loss: 0.27642487114498604\n",
      "Epoch [44/150], Loss: 0.2736321617254095\n",
      "Epoch [45/150], Loss: 0.2728176466919249\n",
      "Epoch [46/150], Loss: 0.2679825532405472\n",
      "Epoch [47/150], Loss: 0.2679906233539029\n",
      "Epoch [48/150], Loss: 0.2649066177013544\n",
      "Epoch [49/150], Loss: 0.26285111735021927\n",
      "Epoch [50/150], Loss: 0.2601390981897227\n",
      "Epoch [51/150], Loss: 0.2577094985448469\n",
      "Epoch [52/150], Loss: 0.25705015913794826\n",
      "Epoch [53/150], Loss: 0.25535324691752126\n",
      "Epoch [54/150], Loss: 0.25238303592196704\n",
      "Epoch [55/150], Loss: 0.2502603543287454\n",
      "Epoch [56/150], Loss: 0.24926005619999583\n",
      "Epoch [57/150], Loss: 0.2450601329919203\n",
      "Epoch [58/150], Loss: 0.24434271744601332\n",
      "Epoch [59/150], Loss: 0.24277506239891955\n",
      "Epoch [60/150], Loss: 0.2421513469216831\n",
      "Epoch [61/150], Loss: 0.23987899521098976\n",
      "Epoch [62/150], Loss: 0.2382692711563165\n",
      "Epoch [63/150], Loss: 0.23638211327708997\n",
      "Epoch [64/150], Loss: 0.23354044216546269\n",
      "Epoch [65/150], Loss: 0.23315322657689103\n",
      "Epoch [66/150], Loss: 0.23146393383865263\n",
      "Epoch [67/150], Loss: 0.23036129077289905\n",
      "Epoch [68/150], Loss: 0.229266324516444\n",
      "Epoch [69/150], Loss: 0.22797964119499375\n",
      "Epoch [70/150], Loss: 0.22594559029205993\n",
      "Epoch [71/150], Loss: 0.2243943082686795\n",
      "Epoch [72/150], Loss: 0.2224786558665922\n",
      "Epoch [73/150], Loss: 0.220545443265694\n",
      "Epoch [74/150], Loss: 0.22112056398045388\n",
      "Epoch [75/150], Loss: 0.21905621368799863\n",
      "Epoch [76/150], Loss: 0.2184569019440581\n",
      "Epoch [77/150], Loss: 0.21757766505050435\n",
      "Epoch [78/150], Loss: 0.2141429961829587\n",
      "Epoch [79/150], Loss: 0.21428647239832208\n",
      "Epoch [80/150], Loss: 0.21274991600846502\n",
      "Epoch [81/150], Loss: 0.211809572573693\n",
      "Epoch [82/150], Loss: 0.21119236470199637\n",
      "Epoch [83/150], Loss: 0.208804564070461\n",
      "Epoch [84/150], Loss: 0.20897647604080702\n",
      "Epoch [85/150], Loss: 0.20805283121987303\n",
      "Epoch [86/150], Loss: 0.20669298935957583\n",
      "Epoch [87/150], Loss: 0.2046216231908911\n",
      "Epoch [88/150], Loss: 0.20359923134764296\n",
      "Epoch [89/150], Loss: 0.20340878127196266\n",
      "Epoch [90/150], Loss: 0.2031079428856125\n",
      "Epoch [91/150], Loss: 0.20119239022858285\n",
      "Epoch [92/150], Loss: 0.1995271149281034\n",
      "Epoch [93/150], Loss: 0.19977218723733434\n",
      "Epoch [94/150], Loss: 0.19868190739841035\n",
      "Epoch [95/150], Loss: 0.19702258032579267\n",
      "Epoch [96/150], Loss: 0.19668841154404557\n",
      "Epoch [97/150], Loss: 0.19574891132011787\n",
      "Epoch [98/150], Loss: 0.1936965313789042\n",
      "Epoch [99/150], Loss: 0.19330545226822868\n",
      "Epoch [100/150], Loss: 0.19322634410735554\n",
      "Epoch [101/150], Loss: 0.19106287582304624\n",
      "Epoch [102/150], Loss: 0.19176852653629733\n",
      "Epoch [103/150], Loss: 0.18907727587584547\n",
      "Epoch [104/150], Loss: 0.18823512753651447\n",
      "Epoch [105/150], Loss: 0.1874058866106716\n",
      "Epoch [106/150], Loss: 0.18771826484300375\n",
      "Epoch [107/150], Loss: 0.18713664122539195\n",
      "Epoch [108/150], Loss: 0.18664116410445422\n",
      "Epoch [109/150], Loss: 0.18594197322239173\n",
      "Epoch [110/150], Loss: 0.18470987861331378\n",
      "Epoch [111/150], Loss: 0.18311106046450126\n",
      "Epoch [112/150], Loss: 0.18280159237812768\n",
      "Epoch [113/150], Loss: 0.18125164360034007\n",
      "Epoch [114/150], Loss: 0.18070775586615007\n",
      "Epoch [115/150], Loss: 0.17949911072319688\n",
      "Epoch [116/150], Loss: 0.17961756442248467\n",
      "Epoch [117/150], Loss: 0.17936703330229162\n",
      "Epoch [118/150], Loss: 0.17718354237402067\n",
      "Epoch [119/150], Loss: 0.1770341810629931\n",
      "Epoch [120/150], Loss: 0.17564138463857915\n",
      "Epoch [121/150], Loss: 0.1741973255624507\n",
      "Epoch [122/150], Loss: 0.17539209761591215\n",
      "Epoch [123/150], Loss: 0.17461469827968903\n",
      "Epoch [124/150], Loss: 0.17316731406166794\n",
      "Epoch [125/150], Loss: 0.17246544154372412\n",
      "Epoch [126/150], Loss: 0.17200884990039048\n",
      "Epoch [127/150], Loss: 0.1725375475112681\n",
      "Epoch [128/150], Loss: 0.17103185789918401\n",
      "Epoch [129/150], Loss: 0.1700603168409216\n",
      "Epoch [130/150], Loss: 0.16909383707592981\n",
      "Epoch [131/150], Loss: 0.16894145770960434\n",
      "Epoch [132/150], Loss: 0.16772042180833038\n",
      "Epoch [133/150], Loss: 0.16763434762360097\n",
      "Epoch [134/150], Loss: 0.16656533235511597\n",
      "Epoch [135/150], Loss: 0.16637444119038022\n",
      "Epoch [136/150], Loss: 0.16501830448725013\n",
      "Epoch [137/150], Loss: 0.16473100322217216\n",
      "Epoch [138/150], Loss: 0.16407310369942207\n",
      "Epoch [139/150], Loss: 0.16338266993241238\n",
      "Epoch [140/150], Loss: 0.16328778662373467\n",
      "Epoch [141/150], Loss: 0.16218681454022105\n",
      "Epoch [142/150], Loss: 0.16179931396032757\n",
      "Epoch [143/150], Loss: 0.16199947012627794\n",
      "Epoch [144/150], Loss: 0.16088962664877363\n",
      "Epoch [145/150], Loss: 0.16143122369670163\n",
      "Epoch [146/150], Loss: 0.16050605903502219\n",
      "Epoch [147/150], Loss: 0.1586748804409229\n",
      "Epoch [148/150], Loss: 0.15804398425183294\n",
      "Epoch [149/150], Loss: 0.15802924568649176\n",
      "Epoch [150/150], Loss: 0.15639584796744188\n",
      "Epoch 150 Accuracy = 93.97%, Loss = 0.5939\n",
      "Epoch [1/25], Loss: inf\n",
      "Epoch [2/25], Loss: 0.80726107912239\n",
      "Epoch [3/25], Loss: 0.6732636462428296\n",
      "Epoch [4/25], Loss: 0.5979670232714465\n",
      "Epoch [5/25], Loss: 0.5496294512233386\n",
      "Epoch [6/25], Loss: 0.5149097523709061\n",
      "Epoch [7/25], Loss: 0.4827486991494564\n",
      "Epoch [8/25], Loss: 0.4596935134330415\n",
      "Epoch [9/25], Loss: 0.4389016393135923\n",
      "Epoch [10/25], Loss: 0.4238616192965225\n",
      "Epoch [11/25], Loss: 0.4110847816397436\n",
      "Epoch [12/25], Loss: 0.39690622153276733\n",
      "Epoch [13/25], Loss: 0.38566650127235336\n",
      "Epoch [14/25], Loss: 0.377534204132496\n",
      "Epoch [15/25], Loss: 0.3666078243215258\n",
      "Epoch [16/25], Loss: 0.3597980045127236\n",
      "Epoch [17/25], Loss: 0.34981509439530784\n",
      "Epoch [18/25], Loss: 0.34351438414078195\n",
      "Epoch [19/25], Loss: 0.33652489617152603\n",
      "Epoch [20/25], Loss: 0.3294994297746137\n",
      "Epoch [21/25], Loss: 0.32311136117530015\n",
      "Epoch [22/25], Loss: 0.3172072541067076\n",
      "Epoch [23/25], Loss: 0.3110306250609865\n",
      "Epoch [24/25], Loss: 0.30669571263385054\n",
      "Epoch [25/25], Loss: 0.3024647772601214\n",
      "Epoch 25 Accuracy = 90.86%, Loss = 0.0273\n",
      "Epoch [1/50], Loss: inf\n",
      "Epoch [2/50], Loss: 0.8287403701110743\n",
      "Epoch [3/50], Loss: 0.6694833156389941\n",
      "Epoch [4/50], Loss: 0.5863352699682582\n",
      "Epoch [5/50], Loss: 0.53398434072698\n",
      "Epoch [6/50], Loss: 0.4955913424724907\n",
      "Epoch [7/50], Loss: 0.4654436573592636\n",
      "Epoch [8/50], Loss: 0.43873654164690135\n",
      "Epoch [9/50], Loss: 0.4212707557229248\n",
      "Epoch [10/50], Loss: 0.4036537504106406\n",
      "Epoch [11/50], Loss: 0.3874634803440713\n",
      "Epoch [12/50], Loss: 0.3752392392643281\n",
      "Epoch [13/50], Loss: 0.36487554939192585\n",
      "Epoch [14/50], Loss: 0.35355478662260187\n",
      "Epoch [15/50], Loss: 0.3425184598013196\n",
      "Epoch [16/50], Loss: 0.3346333334708276\n",
      "Epoch [17/50], Loss: 0.3275196529344848\n",
      "Epoch [18/50], Loss: 0.3174142808270117\n",
      "Epoch [19/50], Loss: 0.30932512615065694\n",
      "Epoch [20/50], Loss: 0.3034256361766614\n",
      "Epoch [21/50], Loss: 0.2972118332533088\n",
      "Epoch [22/50], Loss: 0.2907951470441112\n",
      "Epoch [23/50], Loss: 0.287135626084991\n",
      "Epoch [24/50], Loss: 0.2800854464861089\n",
      "Epoch [25/50], Loss: 0.2753960410422393\n",
      "Epoch [26/50], Loss: 0.26977664738697543\n",
      "Epoch [27/50], Loss: 0.265703133605212\n",
      "Epoch [28/50], Loss: 0.2619332488484118\n",
      "Epoch [29/50], Loss: 0.25769198659407994\n",
      "Epoch [30/50], Loss: 0.2546000664669943\n",
      "Epoch [31/50], Loss: 0.2490449619260362\n",
      "Epoch [32/50], Loss: 0.24631424238828187\n",
      "Epoch [33/50], Loss: 0.24237864121820288\n",
      "Epoch [34/50], Loss: 0.23797303260486743\n",
      "Epoch [35/50], Loss: 0.23618829981379774\n",
      "Epoch [36/50], Loss: 0.23324767924665019\n",
      "Epoch [37/50], Loss: 0.2281527855236709\n",
      "Epoch [38/50], Loss: 0.2246587157788672\n",
      "Epoch [39/50], Loss: 0.22393297949324853\n",
      "Epoch [40/50], Loss: 0.2201784207666739\n",
      "Epoch [41/50], Loss: 0.21759336023654516\n",
      "Epoch [42/50], Loss: 0.21555343881884984\n",
      "Epoch [43/50], Loss: 0.2134894617086102\n",
      "Epoch [44/50], Loss: 0.21054340110418768\n",
      "Epoch [45/50], Loss: 0.20857636081212452\n",
      "Epoch [46/50], Loss: 0.2064441013648102\n",
      "Epoch [47/50], Loss: 0.20337070569137541\n",
      "Epoch [48/50], Loss: 0.200549798222346\n",
      "Epoch [49/50], Loss: 0.20091593373781264\n",
      "Epoch [50/50], Loss: 0.19697419977737324\n",
      "Epoch 50 Accuracy = 93.16%, Loss = 0.3210\n",
      "Epoch [1/100], Loss: inf\n",
      "Epoch [2/100], Loss: inf\n",
      "Epoch [3/100], Loss: 0.6563035490822513\n",
      "Epoch [4/100], Loss: 0.583807777637577\n",
      "Epoch [5/100], Loss: 0.5334939436345206\n",
      "Epoch [6/100], Loss: 0.49908623994529866\n",
      "Epoch [7/100], Loss: 0.46885298866498243\n",
      "Epoch [8/100], Loss: 0.4455278439353084\n",
      "Epoch [9/100], Loss: 0.42339352689862914\n",
      "Epoch [10/100], Loss: 0.40524914030122455\n",
      "Epoch [11/100], Loss: 0.3893686722770023\n",
      "Epoch [12/100], Loss: 0.3776608317864593\n",
      "Epoch [13/100], Loss: 0.36358485366837706\n",
      "Epoch [14/100], Loss: 0.3525715051153578\n",
      "Epoch [15/100], Loss: 0.341027053725605\n",
      "Epoch [16/100], Loss: 0.33239614431628434\n",
      "Epoch [17/100], Loss: 0.3252995518201642\n",
      "Epoch [18/100], Loss: 0.31527780157752566\n",
      "Epoch [19/100], Loss: 0.30844215555641374\n",
      "Epoch [20/100], Loss: 0.30136699818029955\n",
      "Epoch [21/100], Loss: 0.2951045302270868\n",
      "Epoch [22/100], Loss: 0.29055794358573134\n",
      "Epoch [23/100], Loss: 0.283283357456244\n",
      "Epoch [24/100], Loss: 0.2777227747618987\n",
      "Epoch [25/100], Loss: 0.2728676740322456\n",
      "Epoch [26/100], Loss: 0.2697746533015694\n",
      "Epoch [27/100], Loss: 0.2633466524566174\n",
      "Epoch [28/100], Loss: 0.26044266945316\n",
      "Epoch [29/100], Loss: 0.25598662262332555\n",
      "Epoch [30/100], Loss: 0.25227453605724925\n",
      "Epoch [31/100], Loss: 0.2501846223721756\n",
      "Epoch [32/100], Loss: 0.24475469094372723\n",
      "Epoch [33/100], Loss: 0.24252897994356803\n",
      "Epoch [34/100], Loss: 0.23875536425385507\n",
      "Epoch [35/100], Loss: 0.23580893553697388\n",
      "Epoch [36/100], Loss: 0.23334653179486\n",
      "Epoch [37/100], Loss: 0.22891165526291296\n",
      "Epoch [38/100], Loss: 0.22725198722569864\n",
      "Epoch [39/100], Loss: 0.224082778785921\n",
      "Epoch [40/100], Loss: 0.22114397587674708\n",
      "Epoch [41/100], Loss: 0.21891493515264057\n",
      "Epoch [42/100], Loss: 0.21670884746200075\n",
      "Epoch [43/100], Loss: 0.21376278808016166\n",
      "Epoch [44/100], Loss: 0.21042323633517904\n",
      "Epoch [45/100], Loss: 0.20943021536709178\n",
      "Epoch [46/100], Loss: 0.2082415158527935\n",
      "Epoch [47/100], Loss: 0.20515728221561585\n",
      "Epoch [48/100], Loss: 0.20209044213933763\n",
      "Epoch [49/100], Loss: 0.20016470928467606\n",
      "Epoch [50/100], Loss: 0.1995396480434938\n",
      "Epoch [51/100], Loss: 0.19628994629840357\n",
      "Epoch [52/100], Loss: 0.1943189519054819\n",
      "Epoch [53/100], Loss: 0.19386215313763022\n",
      "Epoch [54/100], Loss: 0.19061746723119238\n",
      "Epoch [55/100], Loss: 0.19067694607665422\n",
      "Epoch [56/100], Loss: 0.18917745792824886\n",
      "Epoch [57/100], Loss: 0.18487821094500517\n",
      "Epoch [58/100], Loss: 0.18416925934392808\n",
      "Epoch [59/100], Loss: 0.18362761320202117\n",
      "Epoch [60/100], Loss: 0.18090116189888492\n",
      "Epoch [61/100], Loss: 0.18026601298741904\n",
      "Epoch [62/100], Loss: 0.17977881819967054\n",
      "Epoch [63/100], Loss: 0.17688971762703173\n",
      "Epoch [64/100], Loss: 0.17456175851643577\n",
      "Epoch [65/100], Loss: 0.17513563866687643\n",
      "Epoch [66/100], Loss: 0.1726976015554816\n",
      "Epoch [67/100], Loss: 0.17207706468597947\n",
      "Epoch [68/100], Loss: 0.16825413073852602\n",
      "Epoch [69/100], Loss: 0.16801471513533792\n",
      "Epoch [70/100], Loss: 0.16660658639749848\n",
      "Epoch [71/100], Loss: 0.1650001037804535\n",
      "Epoch [72/100], Loss: 0.16603078372451818\n",
      "Epoch [73/100], Loss: 0.16390458790956292\n",
      "Epoch [74/100], Loss: 0.16073518005542126\n",
      "Epoch [75/100], Loss: 0.16108960428174213\n",
      "Epoch [76/100], Loss: 0.15923089540940236\n",
      "Epoch [77/100], Loss: 0.15838481425508402\n",
      "Epoch [78/100], Loss: 0.15868881201167945\n",
      "Epoch [79/100], Loss: 0.15568239817524984\n",
      "Epoch [80/100], Loss: 0.15544867104867383\n",
      "Epoch [81/100], Loss: 0.15331090065638092\n",
      "Epoch [82/100], Loss: 0.15221150159967117\n",
      "Epoch [83/100], Loss: 0.1519471243603556\n",
      "Epoch [84/100], Loss: 0.15083938949328815\n",
      "Epoch [85/100], Loss: 0.14979229710960376\n",
      "Epoch [86/100], Loss: 0.14861995506948641\n",
      "Epoch [87/100], Loss: 0.14655590129023344\n",
      "Epoch [88/100], Loss: 0.14706517867280838\n",
      "Epoch [89/100], Loss: 0.14534724707292085\n",
      "Epoch [90/100], Loss: 0.1443910397476396\n",
      "Epoch [91/100], Loss: 0.1429957289400874\n",
      "Epoch [92/100], Loss: 0.14271599213046215\n",
      "Epoch [93/100], Loss: 0.1407839250196327\n",
      "Epoch [94/100], Loss: 0.140746003148166\n",
      "Epoch [95/100], Loss: 0.13939853340901573\n",
      "Epoch [96/100], Loss: 0.13849203712089214\n",
      "Epoch [97/100], Loss: 0.13782093895526426\n",
      "Epoch [98/100], Loss: 0.13762031217534137\n",
      "Epoch [99/100], Loss: 0.13590906363661012\n",
      "Epoch [100/100], Loss: 0.13558061356684264\n",
      "Epoch 100 Accuracy = 94.13%, Loss = 0.0130\n",
      "Epoch [1/150], Loss: inf\n",
      "Epoch [2/150], Loss: inf\n",
      "Epoch [3/150], Loss: inf\n",
      "Epoch [4/150], Loss: inf\n",
      "Epoch [5/150], Loss: 0.5569438502707441\n",
      "Epoch [6/150], Loss: 0.5212399894540043\n",
      "Epoch [7/150], Loss: 0.49278214374392215\n",
      "Epoch [8/150], Loss: 0.46664627401103886\n",
      "Epoch [9/150], Loss: 0.4475646587252656\n",
      "Epoch [10/150], Loss: 0.42919682857297203\n",
      "Epoch [11/150], Loss: 0.41046652453046406\n",
      "Epoch [12/150], Loss: 0.3971072302837492\n",
      "Epoch [13/150], Loss: 0.38509327221731654\n",
      "Epoch [14/150], Loss: 0.37320116943562365\n",
      "Epoch [15/150], Loss: 0.3628871051073244\n",
      "Epoch [16/150], Loss: 0.3554961430723488\n",
      "Epoch [17/150], Loss: 0.34411133667842175\n",
      "Epoch [18/150], Loss: 0.3342577093129997\n",
      "Epoch [19/150], Loss: 0.32818570848492284\n",
      "Epoch [20/150], Loss: 0.32302028827014634\n",
      "Epoch [21/150], Loss: 0.31547153070686423\n",
      "Epoch [22/150], Loss: 0.30878577552081937\n",
      "Epoch [23/150], Loss: 0.3015966574639351\n",
      "Epoch [24/150], Loss: 0.29781338142188424\n",
      "Epoch [25/150], Loss: 0.2915436863955062\n",
      "Epoch [26/150], Loss: 0.28543840927527103\n",
      "Epoch [27/150], Loss: 0.28107012347624794\n",
      "Epoch [28/150], Loss: 0.2772559074457386\n",
      "Epoch [29/150], Loss: 0.27325827521294316\n",
      "Epoch [30/150], Loss: 0.26751930203246593\n",
      "Epoch [31/150], Loss: 0.26703309612977805\n",
      "Epoch [32/150], Loss: 0.26096534333379773\n",
      "Epoch [33/150], Loss: 0.25916044827947676\n",
      "Epoch [34/150], Loss: 0.25315783886130644\n",
      "Epoch [35/150], Loss: 0.24931197108127162\n",
      "Epoch [36/150], Loss: 0.24759703744502015\n",
      "Epoch [37/150], Loss: 0.24579525966179183\n",
      "Epoch [38/150], Loss: 0.24195793499479865\n",
      "Epoch [39/150], Loss: 0.2385632875270603\n",
      "Epoch [40/150], Loss: 0.23620723699278945\n",
      "Epoch [41/150], Loss: 0.2335798884373544\n",
      "Epoch [42/150], Loss: 0.2307052848384495\n",
      "Epoch [43/150], Loss: 0.22749043764742236\n",
      "Epoch [44/150], Loss: 0.22610502532933666\n",
      "Epoch [45/150], Loss: 0.2228242447054848\n",
      "Epoch [46/150], Loss: 0.22006466991208679\n",
      "Epoch [47/150], Loss: 0.2184408240631213\n",
      "Epoch [48/150], Loss: 0.21694523830677886\n",
      "Epoch [49/150], Loss: 0.214805552931534\n",
      "Epoch [50/150], Loss: 0.2122921691534369\n",
      "Epoch [51/150], Loss: 0.21028968428510295\n",
      "Epoch [52/150], Loss: 0.20901264968102382\n",
      "Epoch [53/150], Loss: 0.20778288507398732\n",
      "Epoch [54/150], Loss: 0.20447931928280438\n",
      "Epoch [55/150], Loss: 0.20378881055157702\n",
      "Epoch [56/150], Loss: 0.20104558101506942\n",
      "Epoch [57/150], Loss: 0.19927424001183439\n",
      "Epoch [58/150], Loss: 0.19773053936569582\n",
      "Epoch [59/150], Loss: 0.19554128459954337\n",
      "Epoch [60/150], Loss: 0.1952240802505221\n",
      "Epoch [61/150], Loss: 0.19371646662386835\n",
      "Epoch [62/150], Loss: 0.19287611958069464\n",
      "Epoch [63/150], Loss: 0.1887602059507723\n",
      "Epoch [64/150], Loss: 0.18884163727496828\n",
      "Epoch [65/150], Loss: 0.18741516010920978\n",
      "Epoch [66/150], Loss: 0.1855903322377441\n",
      "Epoch [67/150], Loss: 0.18369560925927725\n",
      "Epoch [68/150], Loss: 0.18280463119446722\n",
      "Epoch [69/150], Loss: 0.18125097433583112\n",
      "Epoch [70/150], Loss: 0.17940124059930773\n",
      "Epoch [71/150], Loss: 0.17851714704490101\n",
      "Epoch [72/150], Loss: 0.17818325919821898\n",
      "Epoch [73/150], Loss: 0.1773599881879348\n",
      "Epoch [74/150], Loss: 0.17429740277632785\n",
      "Epoch [75/150], Loss: 0.17361258569072077\n",
      "Epoch [76/150], Loss: 0.17247481704276393\n",
      "Epoch [77/150], Loss: 0.17118365432301288\n",
      "Epoch [78/150], Loss: 0.16867839620610964\n",
      "Epoch [79/150], Loss: 0.1686680561227413\n",
      "Epoch [80/150], Loss: 0.1670238088570362\n",
      "Epoch [81/150], Loss: 0.1662066392365526\n",
      "Epoch [82/150], Loss: 0.1645821848381059\n",
      "Epoch [83/150], Loss: 0.16413446765417394\n",
      "Epoch [84/150], Loss: 0.16248527889851902\n",
      "Epoch [85/150], Loss: 0.1613479783041433\n",
      "Epoch [86/150], Loss: 0.16078972802716757\n",
      "Epoch [87/150], Loss: 0.16080038970650276\n",
      "Epoch [88/150], Loss: 0.1586255015748511\n",
      "Epoch [89/150], Loss: 0.15752858836213515\n",
      "Epoch [90/150], Loss: 0.15738581839780574\n",
      "Epoch [91/150], Loss: 0.15534046414364638\n",
      "Epoch [92/150], Loss: 0.15401057611682062\n",
      "Epoch [93/150], Loss: 0.15373864504609053\n",
      "Epoch [94/150], Loss: 0.15325976073087622\n",
      "Epoch [95/150], Loss: 0.1518952731562143\n",
      "Epoch [96/150], Loss: 0.15041760257849515\n",
      "Epoch [97/150], Loss: 0.1494184532234758\n",
      "Epoch [98/150], Loss: 0.14902565279130361\n",
      "Epoch [99/150], Loss: 0.14895927767737824\n",
      "Epoch [100/150], Loss: 0.14771343199032222\n",
      "Epoch [101/150], Loss: 0.14682648632832146\n",
      "Epoch [102/150], Loss: 0.14657939164915768\n",
      "Epoch [103/150], Loss: 0.14491264120125227\n",
      "Epoch [104/150], Loss: 0.14388713898565827\n",
      "Epoch [105/150], Loss: 0.14309807803266544\n",
      "Epoch [106/150], Loss: 0.1415561447110807\n",
      "Epoch [107/150], Loss: 0.14080034906059033\n",
      "Epoch [108/150], Loss: 0.14100909272302833\n",
      "Epoch [109/150], Loss: 0.1393445393654059\n",
      "Epoch [110/150], Loss: 0.1382984452710087\n",
      "Epoch [111/150], Loss: 0.139065623974544\n",
      "Epoch [112/150], Loss: 0.13636883323355034\n",
      "Epoch [113/150], Loss: 0.13662179807117247\n",
      "Epoch [114/150], Loss: 0.13497607172019405\n",
      "Epoch [115/150], Loss: 0.1348335241920728\n",
      "Epoch [116/150], Loss: 0.1340869999672265\n",
      "Epoch [117/150], Loss: 0.13378754217257333\n",
      "Epoch [118/150], Loss: 0.13328175424619773\n",
      "Epoch [119/150], Loss: 0.1314930289237462\n",
      "Epoch [120/150], Loss: 0.13152823826640664\n",
      "Epoch [121/150], Loss: 0.13054530794794497\n",
      "Epoch [122/150], Loss: 0.1295779143622361\n",
      "Epoch [123/150], Loss: 0.12977044375207264\n",
      "Epoch [124/150], Loss: 0.12920215942262697\n",
      "Epoch [125/150], Loss: 0.12793498133696576\n",
      "Epoch [126/150], Loss: 0.12752665502438382\n",
      "Epoch [127/150], Loss: 0.12645649627472297\n",
      "Epoch [128/150], Loss: 0.1262717337920329\n",
      "Epoch [129/150], Loss: 0.12441459321317173\n",
      "Epoch [130/150], Loss: 0.12473231680042333\n",
      "Epoch [131/150], Loss: 0.12357938463029253\n",
      "Epoch [132/150], Loss: 0.12341874495611682\n",
      "Epoch [133/150], Loss: 0.12249911199634766\n",
      "Epoch [134/150], Loss: 0.12198664595416236\n",
      "Epoch [135/150], Loss: 0.1219452332753361\n",
      "Epoch [136/150], Loss: 0.12060361237119681\n",
      "Epoch [137/150], Loss: 0.12023927156301852\n",
      "Epoch [138/150], Loss: 0.11891077257213784\n",
      "Epoch [139/150], Loss: 0.11932448344160594\n",
      "Epoch [140/150], Loss: 0.1179081840828156\n",
      "Epoch [141/150], Loss: 0.11719480534602326\n",
      "Epoch [142/150], Loss: 0.11660693435652547\n",
      "Epoch [143/150], Loss: 0.11628847320365344\n",
      "Epoch [144/150], Loss: 0.11596169299339855\n",
      "Epoch [145/150], Loss: 0.11493463164559246\n",
      "Epoch [146/150], Loss: 0.11424377312301408\n",
      "Epoch [147/150], Loss: 0.1142310887263681\n",
      "Epoch [148/150], Loss: 0.11321865627950192\n",
      "Epoch [149/150], Loss: 0.1122640359756383\n",
      "Epoch [150/150], Loss: 0.11227111959907779\n",
      "Epoch 150 Accuracy = 94.89%, Loss = 0.0067\n",
      "Epoch [1/25], Loss: inf\n",
      "Epoch [2/25], Loss: 0.8720956838536755\n",
      "Epoch [3/25], Loss: 0.6791009023478642\n",
      "Epoch [4/25], Loss: 0.5866639314301914\n",
      "Epoch [5/25], Loss: 0.5283816746448186\n",
      "Epoch [6/25], Loss: 0.48140713294692494\n",
      "Epoch [7/25], Loss: 0.4493778338689881\n",
      "Epoch [8/25], Loss: 0.4276216656374163\n",
      "Epoch [9/25], Loss: 0.40078417698276464\n",
      "Epoch [10/25], Loss: 0.3834034002318658\n",
      "Epoch [11/25], Loss: 0.36886067103314174\n",
      "Epoch [12/25], Loss: 0.3544973999063659\n",
      "Epoch [13/25], Loss: 0.34059932331228143\n",
      "Epoch [14/25], Loss: 0.3294522155513023\n",
      "Epoch [15/25], Loss: 0.321402044476364\n",
      "Epoch [16/25], Loss: 0.3081481521799942\n",
      "Epoch [17/25], Loss: 0.3023800717749036\n",
      "Epoch [18/25], Loss: 0.29479124164412984\n",
      "Epoch [19/25], Loss: 0.2881270859569049\n",
      "Epoch [20/25], Loss: 0.282633835259386\n",
      "Epoch [21/25], Loss: 0.27570620575564925\n",
      "Epoch [22/25], Loss: 0.27049901746715477\n",
      "Epoch [23/25], Loss: 0.26528889969723485\n",
      "Epoch [24/25], Loss: 0.2585713212188214\n",
      "Epoch [25/25], Loss: 0.25496587059054826\n",
      "Epoch 25 Accuracy = 91.82%, Loss = 0.1739\n",
      "Epoch [1/50], Loss: inf\n",
      "Epoch [2/50], Loss: 0.9077859689321679\n",
      "Epoch [3/50], Loss: 0.7115192925994633\n",
      "Epoch [4/50], Loss: 0.617310214296546\n",
      "Epoch [5/50], Loss: 0.5561719283195368\n",
      "Epoch [6/50], Loss: 0.5104267296556306\n",
      "Epoch [7/50], Loss: 0.47706401595071657\n",
      "Epoch [8/50], Loss: 0.4487768078543013\n",
      "Epoch [9/50], Loss: 0.42703383714114895\n",
      "Epoch [10/50], Loss: 0.4102754104134607\n",
      "Epoch [11/50], Loss: 0.3921517697648863\n",
      "Epoch [12/50], Loss: 0.37815295030568086\n",
      "Epoch [13/50], Loss: 0.36526406753332896\n",
      "Epoch [14/50], Loss: 0.3546493187434729\n",
      "Epoch [15/50], Loss: 0.34370349025813146\n",
      "Epoch [16/50], Loss: 0.33546874252408937\n",
      "Epoch [17/50], Loss: 0.32316135920921807\n",
      "Epoch [18/50], Loss: 0.3171968313446293\n",
      "Epoch [19/50], Loss: 0.3111226735705956\n",
      "Epoch [20/50], Loss: 0.3042054270474764\n",
      "Epoch [21/50], Loss: 0.2965316215322018\n",
      "Epoch [22/50], Loss: 0.29215461301436396\n",
      "Epoch [23/50], Loss: 0.2856998565793862\n",
      "Epoch [24/50], Loss: 0.27999649423241985\n",
      "Epoch [25/50], Loss: 0.2767315913087271\n",
      "Epoch [26/50], Loss: 0.27160865712205184\n",
      "Epoch [27/50], Loss: 0.26558157599697857\n",
      "Epoch [28/50], Loss: 0.26166295728293576\n",
      "Epoch [29/50], Loss: 0.2576392411535441\n",
      "Epoch [30/50], Loss: 0.25398719048853124\n",
      "Epoch [31/50], Loss: 0.24987608991144497\n",
      "Epoch [32/50], Loss: 0.24771821147064474\n",
      "Epoch [33/50], Loss: 0.2420600946539004\n",
      "Epoch [34/50], Loss: 0.2399807755333095\n",
      "Epoch [35/50], Loss: 0.23555971095179362\n",
      "Epoch [36/50], Loss: 0.23348022037605065\n",
      "Epoch [37/50], Loss: 0.2297899618053998\n",
      "Epoch [38/50], Loss: 0.22903403974466832\n",
      "Epoch [39/50], Loss: 0.2248927927681895\n",
      "Epoch [40/50], Loss: 0.22188044196281892\n",
      "Epoch [41/50], Loss: 0.22122346534706835\n",
      "Epoch [42/50], Loss: 0.21840198187139565\n",
      "Epoch [43/50], Loss: 0.21651493823406054\n",
      "Epoch [44/50], Loss: 0.2129993737738323\n",
      "Epoch [45/50], Loss: 0.2103558185738778\n",
      "Epoch [46/50], Loss: 0.2080511063421436\n",
      "Epoch [47/50], Loss: 0.2062209166697321\n",
      "Epoch [48/50], Loss: 0.20399371897283647\n",
      "Epoch [49/50], Loss: 0.20081934079479288\n",
      "Epoch [50/50], Loss: 0.19877845061474483\n",
      "Epoch 50 Accuracy = 91.18%, Loss = 0.4614\n",
      "Epoch [1/100], Loss: inf\n",
      "Epoch [2/100], Loss: 0.8566553314964209\n",
      "Epoch [3/100], Loss: 0.6470443135750054\n",
      "Epoch [4/100], Loss: 0.5587701385145386\n",
      "Epoch [5/100], Loss: 0.5033183588527027\n",
      "Epoch [6/100], Loss: 0.46787057566829027\n",
      "Epoch [7/100], Loss: 0.4380920951440445\n",
      "Epoch [8/100], Loss: 0.41246401352758644\n",
      "Epoch [9/100], Loss: 0.39257075258033003\n",
      "Epoch [10/100], Loss: 0.37421647891752463\n",
      "Epoch [11/100], Loss: 0.3598198933864951\n",
      "Epoch [12/100], Loss: 0.3460109398103862\n",
      "Epoch [13/100], Loss: 0.33546423194314895\n",
      "Epoch [14/100], Loss: 0.32346454053147683\n",
      "Epoch [15/100], Loss: 0.315792725103073\n",
      "Epoch [16/100], Loss: 0.3051860786178683\n",
      "Epoch [17/100], Loss: 0.2991151467617565\n",
      "Epoch [18/100], Loss: 0.2909234436693077\n",
      "Epoch [19/100], Loss: 0.28415456958613505\n",
      "Epoch [20/100], Loss: 0.2767861649042449\n",
      "Epoch [21/100], Loss: 0.2706753198778242\n",
      "Epoch [22/100], Loss: 0.26598368090154206\n",
      "Epoch [23/100], Loss: 0.25850884952839864\n",
      "Epoch [24/100], Loss: 0.254862113190194\n",
      "Epoch [25/100], Loss: 0.250136935551338\n",
      "Epoch [26/100], Loss: 0.2444722546238748\n",
      "Epoch [27/100], Loss: 0.24292668034508824\n",
      "Epoch [28/100], Loss: 0.23680396173054882\n",
      "Epoch [29/100], Loss: 0.23251088570253342\n",
      "Epoch [30/100], Loss: 0.2280781238444973\n",
      "Epoch [31/100], Loss: 0.2263352016547839\n",
      "Epoch [32/100], Loss: 0.22176307925700348\n",
      "Epoch [33/100], Loss: 0.21848672324272153\n",
      "Epoch [34/100], Loss: 0.21632022727856595\n",
      "Epoch [35/100], Loss: 0.21184216947969192\n",
      "Epoch [36/100], Loss: 0.21103974789197127\n",
      "Epoch [37/100], Loss: 0.20636664234180233\n",
      "Epoch [38/100], Loss: 0.20363061943817715\n",
      "Epoch [39/100], Loss: 0.20216278043186078\n",
      "Epoch [40/100], Loss: 0.19752912003199405\n",
      "Epoch [41/100], Loss: 0.19642529981173357\n",
      "Epoch [42/100], Loss: 0.19402408823935668\n",
      "Epoch [43/100], Loss: 0.19024412880111172\n",
      "Epoch [44/100], Loss: 0.1891014355948173\n",
      "Epoch [45/100], Loss: 0.1865604377879666\n",
      "Epoch [46/100], Loss: 0.18339047438549097\n",
      "Epoch [47/100], Loss: 0.18222025941238523\n",
      "Epoch [48/100], Loss: 0.180306132830536\n",
      "Epoch [49/100], Loss: 0.17794367237410338\n",
      "Epoch [50/100], Loss: 0.17601949193273428\n",
      "Epoch [51/100], Loss: 0.1755704726131862\n",
      "Epoch [52/100], Loss: 0.17145841483597193\n",
      "Epoch [53/100], Loss: 0.17018842495115497\n",
      "Epoch [54/100], Loss: 0.16989547076936606\n",
      "Epoch [55/100], Loss: 0.16704970666295063\n",
      "Epoch [56/100], Loss: 0.16413475196903832\n",
      "Epoch [57/100], Loss: 0.16333773531539253\n",
      "Epoch [58/100], Loss: 0.16197288796286102\n",
      "Epoch [59/100], Loss: 0.16062917751440425\n",
      "Epoch [60/100], Loss: 0.1594621851081544\n",
      "Epoch [61/100], Loss: 0.1559765649072727\n",
      "Epoch [62/100], Loss: 0.15417999806018248\n",
      "Epoch [63/100], Loss: 0.15375603989362252\n",
      "Epoch [64/100], Loss: 0.1518589611015932\n",
      "Epoch [65/100], Loss: 0.15078659511893874\n",
      "Epoch [66/100], Loss: 0.14847144654051378\n",
      "Epoch [67/100], Loss: 0.14709330341515245\n",
      "Epoch [68/100], Loss: 0.14621855334191594\n",
      "Epoch [69/100], Loss: 0.14448977992574524\n",
      "Epoch [70/100], Loss: 0.14339272194218347\n",
      "Epoch [71/100], Loss: 0.14289194873417643\n",
      "Epoch [72/100], Loss: 0.1413769044419273\n",
      "Epoch [73/100], Loss: 0.1401227655132759\n",
      "Epoch [74/100], Loss: 0.13825003452591925\n",
      "Epoch [75/100], Loss: 0.13723786999844984\n",
      "Epoch [76/100], Loss: 0.1358100100330524\n",
      "Epoch [77/100], Loss: 0.13571787477028366\n",
      "Epoch [78/100], Loss: 0.13395777168338138\n",
      "Epoch [79/100], Loss: 0.13338738229119734\n",
      "Epoch [80/100], Loss: 0.13184067921745773\n",
      "Epoch [81/100], Loss: 0.1310556232561118\n",
      "Epoch [82/100], Loss: 0.12830603485136438\n",
      "Epoch [83/100], Loss: 0.1273333701700152\n",
      "Epoch [84/100], Loss: 0.12811209606325238\n",
      "Epoch [85/100], Loss: 0.1263477361891531\n",
      "Epoch [86/100], Loss: 0.12502972042342958\n",
      "Epoch [87/100], Loss: 0.12290735169507362\n",
      "Epoch [88/100], Loss: 0.12317178335526577\n",
      "Epoch [89/100], Loss: 0.12241621535621212\n",
      "Epoch [90/100], Loss: 0.11997268144096837\n",
      "Epoch [91/100], Loss: 0.12025659491097543\n",
      "Epoch [92/100], Loss: 0.11915488778789919\n",
      "Epoch [93/100], Loss: 0.11778317758890222\n",
      "Epoch [94/100], Loss: 0.11755572143456387\n",
      "Epoch [95/100], Loss: 0.1151892437009511\n",
      "Epoch [96/100], Loss: 0.11465490161826832\n",
      "Epoch [97/100], Loss: 0.11495290797989957\n",
      "Epoch [98/100], Loss: 0.11297530735586046\n",
      "Epoch [99/100], Loss: 0.11173633192084848\n",
      "Epoch [100/100], Loss: 0.11094795127821275\n",
      "Epoch 100 Accuracy = 94.56%, Loss = 0.0085\n",
      "Epoch [1/150], Loss: inf\n",
      "Epoch [2/150], Loss: 0.8917426522711854\n",
      "Epoch [3/150], Loss: 0.6545297164878964\n",
      "Epoch [4/150], Loss: 0.5566276762760051\n",
      "Epoch [5/150], Loss: 0.4976716914369899\n",
      "Epoch [6/150], Loss: 0.4606702480212504\n",
      "Epoch [7/150], Loss: 0.4349118007228923\n",
      "Epoch [8/150], Loss: 0.413575599953052\n",
      "Epoch [9/150], Loss: 0.3897561695558155\n",
      "Epoch [10/150], Loss: 0.37621237538039953\n",
      "Epoch [11/150], Loss: 0.36182985200491385\n",
      "Epoch [12/150], Loss: 0.3514510733593973\n",
      "Epoch [13/150], Loss: 0.33842832756637653\n",
      "Epoch [14/150], Loss: 0.3267751924701297\n",
      "Epoch [15/150], Loss: 0.31805096535214883\n",
      "Epoch [16/150], Loss: 0.31063807297447055\n",
      "Epoch [17/150], Loss: 0.3030803196418201\n",
      "Epoch [18/150], Loss: 0.29699127028768757\n",
      "Epoch [19/150], Loss: 0.28917451348422524\n",
      "Epoch [20/150], Loss: 0.28188526667080077\n",
      "Epoch [21/150], Loss: 0.2763087882148405\n",
      "Epoch [22/150], Loss: 0.2712710730468122\n",
      "Epoch [23/150], Loss: 0.26660431802205375\n",
      "Epoch [24/150], Loss: 0.25968724679919253\n",
      "Epoch [25/150], Loss: 0.2560793716648332\n",
      "Epoch [26/150], Loss: 0.25243632106021324\n",
      "Epoch [27/150], Loss: 0.24859363465112982\n",
      "Epoch [28/150], Loss: 0.24134375815444947\n",
      "Epoch [29/150], Loss: 0.23977653622616102\n",
      "Epoch [30/150], Loss: 0.237019912751246\n",
      "Epoch [31/150], Loss: 0.23218123288308803\n",
      "Epoch [32/150], Loss: 0.22988692807145222\n",
      "Epoch [33/150], Loss: 0.2257279472483589\n",
      "Epoch [34/150], Loss: 0.22214370588008509\n",
      "Epoch [35/150], Loss: 0.22034346327911894\n",
      "Epoch [36/150], Loss: 0.2152088033935767\n",
      "Epoch [37/150], Loss: 0.2133566077353777\n",
      "Epoch [38/150], Loss: 0.21058792182003042\n",
      "Epoch [39/150], Loss: 0.20900858244925377\n",
      "Epoch [40/150], Loss: 0.2054680811049302\n",
      "Epoch [41/150], Loss: 0.2042674674094839\n",
      "Epoch [42/150], Loss: 0.19988692490879717\n",
      "Epoch [43/150], Loss: 0.19861240361693006\n",
      "Epoch [44/150], Loss: 0.1951152761307482\n",
      "Epoch [45/150], Loss: 0.19393257312547577\n",
      "Epoch [46/150], Loss: 0.19107651468017622\n",
      "Epoch [47/150], Loss: 0.18980052586511373\n",
      "Epoch [48/150], Loss: 0.18775902111491086\n",
      "Epoch [49/150], Loss: 0.1845446955920479\n",
      "Epoch [50/150], Loss: 0.18322628164605143\n",
      "Epoch [51/150], Loss: 0.18045669322807165\n",
      "Epoch [52/150], Loss: 0.17918566156007668\n",
      "Epoch [53/150], Loss: 0.17767861498156465\n",
      "Epoch [54/150], Loss: 0.1754632442224368\n",
      "Epoch [55/150], Loss: 0.1732783827077028\n",
      "Epoch [56/150], Loss: 0.172435975580145\n",
      "Epoch [57/150], Loss: 0.17105326635721\n",
      "Epoch [58/150], Loss: 0.16897912214355013\n",
      "Epoch [59/150], Loss: 0.1661063941790626\n",
      "Epoch [60/150], Loss: 0.16564401217528985\n",
      "Epoch [61/150], Loss: 0.16379966929434728\n",
      "Epoch [62/150], Loss: 0.16133775914268897\n",
      "Epoch [63/150], Loss: 0.1610903479104518\n",
      "Epoch [64/150], Loss: 0.15863530707749124\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]\n",
    "accuracies_epoch = []\n",
    "accuracies_hidden = []\n",
    "\n",
    "# Define the model architecture\n",
    "input_size = 784\n",
    "output_size = len(trainloader.dataset.classes)\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    accuracies_epoch_for_hidden = []\n",
    "    for epochs in epochs_list:\n",
    "        # Initialize weights with random values\n",
    "        w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "        w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_loss = 0.0\n",
    "            for images, labels in trainloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                # Forward pass\n",
    "                h = images.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                y_pred_sf = y_pred.softmax(dim=1)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                # Backpropagation\n",
    "                grad_y_pred = y_pred_sf.clone()\n",
    "                grad_y_pred[range(images.shape[0]), labels] -= 1  # Derivative of cross-entropy loss w.r.t. y_pred\n",
    "                grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "                grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "                grad_h = grad_h_relu * (h > 0).float()  # Derivative of ReLU activation\n",
    "                grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                # Update weights manually\n",
    "                with torch.no_grad():\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(trainloader)}')\n",
    "\n",
    "        # Evaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                # Forward pass with ReLU activation\n",
    "                h = x.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                total += y.size(0)\n",
    "                correct += (predictions == y).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        accuracies_epoch_for_hidden.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy = {accuracy:.2f}%, Loss = {loss:.4f}\")\n",
    "\n",
    "    accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "\n",
    "# Plot the accuracy against the number of epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    plt.plot(epochs_list, accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Epochs for Different Hidden Layer Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy against the number of hidden layers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, epoch in enumerate(epochs_list):\n",
    "    plt.plot(hidden_sizes, [accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Hidden Layers for Different Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUrkOXbzDRyC"
   },
   "source": [
    "Now after finishing mini-batch gradient we are moving to stochastic gradient.\n",
    "Similar to mini-batch we are using Epoch size as 25, 50, 100, 150 and Hidden layer neurons as 25, 50, 100, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkTnI0gpC0CN"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ixgoh6AQDng9"
   },
   "source": [
    "Further we will code for:\n",
    "\n",
    "Activation function - Tanh\n",
    "\n",
    "Epoch - 25, 50, 100, 150\n",
    "\n",
    "Hidden layer - 25, 50, 100, 150\n",
    "\n",
    "Stochastic Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJMp4WNqC0em"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]\n",
    "accuracies_epoch = []\n",
    "accuracies_hidden = []\n",
    "\n",
    "# Define the model architecture\n",
    "input_size = 784\n",
    "output_size = len(trainloader.dataset.classes)\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    accuracies_epoch_for_hidden = []\n",
    "    for epochs in epochs_list:\n",
    "        # Initialize weights with random values\n",
    "        w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "        w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_loss = 0.0\n",
    "            for images, labels in trainloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                # Forward pass\n",
    "                h = images.mm(w1)\n",
    "                h_tan = h.tanh()\n",
    "                y_pred = h_tan.mm(w2)\n",
    "                y_pred_sf = y_pred.softmax(dim=1)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                # Backpropagation\n",
    "                grad_y_pred = y_pred_sf.clone()\n",
    "                grad_y_pred[range(images.shape[0]), labels] -= 1\n",
    "                grad_w2 = h_tan.t().mm(grad_y_pred)\n",
    "                grad_h_tan = grad_y_pred.mm(w2.t())\n",
    "                grad_h = grad_h_tan * (1 - h_tan**2)\n",
    "                grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                # Update weights manually\n",
    "                with torch.no_grad():\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(trainloader)}')\n",
    "\n",
    "        # Evaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                h_tan = x.mm(w1).tanh()\n",
    "                y_pred = h_tan.mm(w2)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                total += y.size(0)\n",
    "                correct += (predictions == y).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        accuracies_epoch_for_hidden.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy = {accuracy:.2f}%, Loss = {loss:.4f}\")\n",
    "\n",
    "    accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "\n",
    "# Plot the accuracy against the number of epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    plt.plot(epochs_list, accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Epochs for Different Hidden Layer Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy against the number of hidden layers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, epoch in enumerate(epochs_list):\n",
    "    plt.plot(hidden_sizes, [accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Hidden Layers for Different Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNgMtydqEV3f"
   },
   "source": [
    "Activation function - Relu\n",
    "\n",
    "Epoch - 25, 50, 100, 150\n",
    "\n",
    "Hidden layer - 25, 50, 100, 150\n",
    "\n",
    "Stochastic Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrTI8kQHDO7K"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]\n",
    "accuracies_epoch = []\n",
    "accuracies_hidden = []\n",
    "\n",
    "# Define the model architecture\n",
    "input_size = 784\n",
    "output_size = len(trainloader.dataset.classes)\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    accuracies_epoch_for_hidden = []\n",
    "    for epochs in epochs_list:\n",
    "        # Initialize weights with random values\n",
    "        w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "        w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_loss = 0.0\n",
    "            for images, labels in trainloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                # Forward pass\n",
    "                h = images.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                y_pred_sf = y_pred.softmax(dim=1)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                # Backpropagation\n",
    "                grad_y_pred = y_pred_sf.clone()\n",
    "                grad_y_pred[range(images.shape[0]), labels] -= 1  # Derivative of cross-entropy loss w.r.t. y_pred\n",
    "                grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "                grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "                grad_h = grad_h_relu * (h > 0).float()  # Derivative of ReLU activation\n",
    "                grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                # Update weights manually\n",
    "                with torch.no_grad():\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(trainloader)}')\n",
    "\n",
    "        # Evaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                # Forward pass with ReLU activation\n",
    "                h = x.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                total += y.size(0)\n",
    "                correct += (predictions == y).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        accuracies_epoch_for_hidden.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy = {accuracy:.2f}%, Loss = {loss:.4f}\")\n",
    "\n",
    "    accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "\n",
    "# Plot the accuracy against the number of epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    plt.plot(epochs_list, accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Epochs for Different Hidden Layer Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy against the number of hidden layers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, epoch in enumerate(epochs_list):\n",
    "    plt.plot(hidden_sizes, [accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Hidden Layers for Different Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
