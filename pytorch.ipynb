{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5FjHhNkIZ30t"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8Yfpvkx1Z9po"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yr8FvwxBaJER"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BEqYNm2BlG4"
   },
   "source": [
    "Here we are performing mini-batch gradient with batch size of 10.\n",
    "\n",
    "Below is the code for tanh activation function with epoch size of 25, 50, 100, 150 and fluctuating hidden layer size with number of neurons as 25, 50, 100, 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input, w1, w2, activation='tanh'):\n",
    "    h = input.mm(w1)\n",
    "    if activation == 'tanh':\n",
    "        h_activation = h.tanh()\n",
    "    elif activation == 'relu':\n",
    "        h_activation = h.clamp(min=0)\n",
    "    y_pred = h_activation.mm(w2)\n",
    "    y_pred_sf = y_pred.softmax(dim=1)\n",
    "    return y_pred_sf, h_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(grad_output, h_activation, w2, activation='tanh'):\n",
    "    if activation == 'tanh':\n",
    "        grad_h = grad_output.mm(w2.t()) * (1 - h_activation.tanh() ** 2)\n",
    "    elif activation == 'relu':\n",
    "        grad_h = grad_output.mm(w2.t()) * (h_activation > 0).float()\n",
    "    return grad_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: tanh, Epoch: 1/25, Loss: 0.6945\n",
      "Activation: tanh, Epoch: 10/25, Loss: 0.9142\n",
      "Activation: tanh, Epoch: 20/25, Loss: 0.6249\n",
      "Activation: tanh, Epoch: 25/25, Loss: 0.6739\n",
      "Activation: tanh, Epoch: 1/50, Loss: 0.5501\n",
      "Activation: tanh, Epoch: 10/50, Loss: 0.1502\n",
      "Activation: tanh, Epoch: 20/50, Loss: 0.3340\n",
      "Activation: tanh, Epoch: 30/50, Loss: 2.1500\n",
      "Activation: tanh, Epoch: 40/50, Loss: 0.1789\n",
      "Activation: tanh, Epoch: 50/50, Loss: 0.2024\n",
      "Activation: tanh, Epoch: 1/100, Loss: 0.6815\n",
      "Activation: tanh, Epoch: 10/100, Loss: 0.1112\n",
      "Activation: tanh, Epoch: 20/100, Loss: 0.4918\n",
      "Activation: tanh, Epoch: 30/100, Loss: 0.2053\n",
      "Activation: tanh, Epoch: 40/100, Loss: 1.0827\n"
     ]
    }
   ],
   "source": [
    "for activation_function in ['tanh', 'relu']:\n",
    "    all_accuracies_epoch = []\n",
    "\n",
    "    for hidden_size in hidden_sizes:\n",
    "        accuracies_epoch_for_hidden = []\n",
    "\n",
    "        for epochs in epochs_list:\n",
    "            # Initialize weights\n",
    "            w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "            w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                # Training loop\n",
    "                for images, labels in trainloader:\n",
    "                    images = images.view(images.shape[0], -1)\n",
    "                    y_pred_sf, h_activation = forward(images, w1, w2, activation=activation_function)\n",
    "                    loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                    # Backward pass\n",
    "                    grad_y_pred = y_pred_sf.clone()\n",
    "                    grad_y_pred[range(images.shape[0]), labels] -= 1\n",
    "                    grad_w2 = h_activation.t().mm(grad_y_pred)\n",
    "                    grad_h = backward(grad_y_pred, h_activation, w2, activation=activation_function)\n",
    "                    grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                    # Update weights\n",
    "                    with torch.no_grad():\n",
    "                        w1 = w1 - learning_rate * grad_w1\n",
    "                        w2 = w2 - learning_rate * grad_w2\n",
    "\n",
    "                # Check for every 50 epochs to print the progress\n",
    "                if (epoch + 1) % 10 == 0 or epoch == 0 or epoch + 1 == epochs:\n",
    "                    print(f'Activation: {activation_function}, Epoch: {epoch + 1}/{epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "            # Evaluation loop\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in testloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                y_pred_sf, _ = forward(images, w1, w2, activation=activation_function)\n",
    "                predictions = y_pred_sf.argmax(dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "            \n",
    "            accuracy = (correct / total) * 100\n",
    "            accuracies_epoch_for_hidden.append(accuracy)\n",
    "        \n",
    "        all_accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "    \n",
    "    # Plot accuracy vs. number of epochs for different hidden layer sizes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, hidden_size in enumerate(hidden_sizes):\n",
    "        plt.plot(epochs_list, all_accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(f'Accuracy vs. Number of Epochs for Different Hidden Layer Sizes using {activation_function.upper()} activation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot accuracy vs. number of hidden layers for different epochs\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, epoch in enumerate(epochs_list):\n",
    "        plt.plot(hidden_sizes, [all_accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "    plt.xlabel('Number of Hidden Layers')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(f'Accuracy vs. Number of Hidden Layers for Different Epochs using {activation_function.upper()} activation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hV2DTv3Zb9AL",
    "outputId": "bb62a444-98e9-4f01-def0-3d6412eb6d89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 2.0974880752364795\n",
      "Epoch [2/25], Loss: 1.3303016740878424\n",
      "Epoch [3/25], Loss: 1.0831014469688138\n",
      "Epoch [4/25], Loss: 0.9503337954630454\n",
      "Epoch [5/25], Loss: 0.8667799733765423\n",
      "Epoch [6/25], Loss: 0.8049362244481841\n",
      "Epoch [7/25], Loss: 0.7573151997886598\n",
      "Epoch [8/25], Loss: 0.715014147259295\n",
      "Epoch [9/25], Loss: 0.68192821407939\n",
      "Epoch [10/25], Loss: 0.6532106630106767\n",
      "Epoch [11/25], Loss: 0.626706531536455\n",
      "Epoch [12/25], Loss: 0.6059293484377364\n",
      "Epoch [13/25], Loss: 0.5900384186127533\n",
      "Epoch [14/25], Loss: 0.5732725455220788\n",
      "Epoch [15/25], Loss: 0.5610282144378871\n",
      "Epoch [16/25], Loss: 0.5489829223540922\n",
      "Epoch [17/25], Loss: 0.5376967935990542\n",
      "Epoch [18/25], Loss: 0.5270814560881505\n",
      "Epoch [19/25], Loss: 0.5175004238349696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4272\\706802824.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;31m# Compute the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_sf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;31m# Backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]\n",
    "accuracies_epoch = []\n",
    "accuracies_hidden = []\n",
    "\n",
    "# Define the model architecture\n",
    "input_size = 784\n",
    "output_size = len(trainloader.dataset.classes)\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    accuracies_epoch_for_hidden = []\n",
    "    for epochs in epochs_list:\n",
    "        # Initialize weights with random values\n",
    "        w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "        w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_loss = 0.0\n",
    "            for images, labels in trainloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                # Forward pass\n",
    "                h = images.mm(w1)\n",
    "                h_tan = h.tanh()\n",
    "                y_pred = h_tan.mm(w2)\n",
    "                y_pred_sf = y_pred.softmax(dim=1)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                # Backpropagation\n",
    "                grad_y_pred = y_pred_sf.clone()\n",
    "                grad_y_pred[range(images.shape[0]), labels] -= 1\n",
    "                grad_w2 = h_tan.t().mm(grad_y_pred)\n",
    "                grad_h_tan = grad_y_pred.mm(w2.t())\n",
    "                grad_h = grad_h_tan * (1 - h_tan**2)\n",
    "                grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                # Update weights manually\n",
    "                with torch.no_grad():\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(trainloader)}')\n",
    "\n",
    "        # Evaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                h_tan = x.mm(w1).tanh()\n",
    "                y_pred = h_tan.mm(w2)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                total += y.size(0)\n",
    "                correct += (predictions == y).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        accuracies_epoch_for_hidden.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy = {accuracy:.2f}%, Loss = {loss:.4f}\")\n",
    "\n",
    "    accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "\n",
    "# Plot the accuracy against the number of epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    plt.plot(epochs_list, accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Epochs for Different Hidden Layer Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy against the number of hidden layers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, epoch in enumerate(epochs_list):\n",
    "    plt.plot(hidden_sizes, [accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Hidden Layers for Different Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppBHlM08CZDw"
   },
   "source": [
    "Below is the code for relu activation function with mini-batch gradient - batch size is 10. Epochs are 25, 50, 100, 150 and Hidden layer neurons count as  25, 50, 100, 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3ftSnBcabAs",
    "outputId": "02f6fd65-4db8-4d03-8571-e74d9c6d0af4"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]\n",
    "accuracies_epoch = []\n",
    "accuracies_hidden = []\n",
    "\n",
    "# Define the model architecture\n",
    "input_size = 784\n",
    "output_size = len(trainloader.dataset.classes)\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    accuracies_epoch_for_hidden = []\n",
    "    for epochs in epochs_list:\n",
    "        # Initialize weights with random values\n",
    "        w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "        w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_loss = 0.0\n",
    "            for images, labels in trainloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                # Forward pass\n",
    "                h = images.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                y_pred_sf = y_pred.softmax(dim=1)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                # Backpropagation\n",
    "                grad_y_pred = y_pred_sf.clone()\n",
    "                grad_y_pred[range(images.shape[0]), labels] -= 1  # Derivative of cross-entropy loss w.r.t. y_pred\n",
    "                grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "                grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "                grad_h = grad_h_relu * (h > 0).float()  # Derivative of ReLU activation\n",
    "                grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                # Update weights manually\n",
    "                with torch.no_grad():\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(trainloader)}')\n",
    "\n",
    "        # Evaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                # Forward pass with ReLU activation\n",
    "                h = x.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                total += y.size(0)\n",
    "                correct += (predictions == y).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        accuracies_epoch_for_hidden.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy = {accuracy:.2f}%, Loss = {loss:.4f}\")\n",
    "\n",
    "    accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "\n",
    "# Plot the accuracy against the number of epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    plt.plot(epochs_list, accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Epochs for Different Hidden Layer Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy against the number of hidden layers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, epoch in enumerate(epochs_list):\n",
    "    plt.plot(hidden_sizes, [accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Hidden Layers for Different Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUrkOXbzDRyC"
   },
   "source": [
    "Now after finishing mini-batch gradient we are moving to stochastic gradient.\n",
    "Similar to mini-batch we are using Epoch size as 25, 50, 100, 150 and Hidden layer neurons as 25, 50, 100, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkTnI0gpC0CN"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ixgoh6AQDng9"
   },
   "source": [
    "Further we will code for:\n",
    "\n",
    "Activation function - Tanh\n",
    "\n",
    "Epoch - 25, 50, 100, 150\n",
    "\n",
    "Hidden layer - 25, 50, 100, 150\n",
    "\n",
    "Stochastic Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJMp4WNqC0em"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]\n",
    "accuracies_epoch = []\n",
    "accuracies_hidden = []\n",
    "\n",
    "# Define the model architecture\n",
    "input_size = 784\n",
    "output_size = len(trainloader.dataset.classes)\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    accuracies_epoch_for_hidden = []\n",
    "    for epochs in epochs_list:\n",
    "        # Initialize weights with random values\n",
    "        w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "        w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_loss = 0.0\n",
    "            for images, labels in trainloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                # Forward pass\n",
    "                h = images.mm(w1)\n",
    "                h_tan = h.tanh()\n",
    "                y_pred = h_tan.mm(w2)\n",
    "                y_pred_sf = y_pred.softmax(dim=1)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                # Backpropagation\n",
    "                grad_y_pred = y_pred_sf.clone()\n",
    "                grad_y_pred[range(images.shape[0]), labels] -= 1\n",
    "                grad_w2 = h_tan.t().mm(grad_y_pred)\n",
    "                grad_h_tan = grad_y_pred.mm(w2.t())\n",
    "                grad_h = grad_h_tan * (1 - h_tan**2)\n",
    "                grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                # Update weights manually\n",
    "                with torch.no_grad():\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(trainloader)}')\n",
    "\n",
    "        # Evaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                h_tan = x.mm(w1).tanh()\n",
    "                y_pred = h_tan.mm(w2)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                total += y.size(0)\n",
    "                correct += (predictions == y).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        accuracies_epoch_for_hidden.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy = {accuracy:.2f}%, Loss = {loss:.4f}\")\n",
    "\n",
    "    accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "\n",
    "# Plot the accuracy against the number of epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    plt.plot(epochs_list, accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Epochs for Different Hidden Layer Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy against the number of hidden layers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, epoch in enumerate(epochs_list):\n",
    "    plt.plot(hidden_sizes, [accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Hidden Layers for Different Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNgMtydqEV3f"
   },
   "source": [
    "Activation function - Relu\n",
    "\n",
    "Epoch - 25, 50, 100, 150\n",
    "\n",
    "Hidden layer - 25, 50, 100, 150\n",
    "\n",
    "Stochastic Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrTI8kQHDO7K"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs_list = [25, 50, 100, 150]\n",
    "hidden_sizes = [25, 50, 100, 150]\n",
    "accuracies_epoch = []\n",
    "accuracies_hidden = []\n",
    "\n",
    "# Define the model architecture\n",
    "input_size = 784\n",
    "output_size = len(trainloader.dataset.classes)\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    accuracies_epoch_for_hidden = []\n",
    "    for epochs in epochs_list:\n",
    "        # Initialize weights with random values\n",
    "        w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "        w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_loss = 0.0\n",
    "            for images, labels in trainloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                # Forward pass\n",
    "                h = images.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                y_pred_sf = y_pred.softmax(dim=1)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = -torch.log(y_pred_sf[range(images.shape[0]), labels]).mean()\n",
    "\n",
    "                # Backpropagation\n",
    "                grad_y_pred = y_pred_sf.clone()\n",
    "                grad_y_pred[range(images.shape[0]), labels] -= 1  # Derivative of cross-entropy loss w.r.t. y_pred\n",
    "                grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "                grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "                grad_h = grad_h_relu * (h > 0).float()  # Derivative of ReLU activation\n",
    "                grad_w1 = images.t().mm(grad_h)\n",
    "\n",
    "                # Update weights manually\n",
    "                with torch.no_grad():\n",
    "                    w1 -= learning_rate * grad_w1\n",
    "                    w2 -= learning_rate * grad_w2\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(trainloader)}')\n",
    "\n",
    "        # Evaluation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "                # Forward pass with ReLU activation\n",
    "                h = x.mm(w1)\n",
    "                h_relu = h.clamp(min=0)\n",
    "                y_pred = h_relu.mm(w2)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                total += y.size(0)\n",
    "                correct += (predictions == y).sum().item()\n",
    "\n",
    "        accuracy = (correct / total) * 100\n",
    "        accuracies_epoch_for_hidden.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Accuracy = {accuracy:.2f}%, Loss = {loss:.4f}\")\n",
    "\n",
    "    accuracies_epoch.append(accuracies_epoch_for_hidden)\n",
    "\n",
    "# Plot the accuracy against the number of epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    plt.plot(epochs_list, accuracies_epoch[i], marker='o', label=f'Hidden Layers = {hidden_size}')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Epochs for Different Hidden Layer Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy against the number of hidden layers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, epoch in enumerate(epochs_list):\n",
    "    plt.plot(hidden_sizes, [accuracies_epoch[j][i] for j in range(len(hidden_sizes))], marker='o', label=f'Epochs = {epoch}')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy vs. Number of Hidden Layers for Different Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
